{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instance type\n",
    "\n",
    "vCPU\t             GPU\tMem (GiB)\tGPU Mem (GiB)\tNetwork Performance\n",
    "ml.p3.2xlarge\t8\t1xV100\t61\t         6\t            Up to 10 Gbps\n",
    "\n",
    "Standard Instances - Current Generation\tPrice per Hour\n",
    "ml.p3.2xlarge\t                        $4.627\n",
    "- Contains GPU tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Sep 29 20:45:07 2018 Read files...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import boto\n",
    "import os\n",
    "import itertools\n",
    "import random\n",
    "from random import shuffle\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Embedding, concatenate, Flatten, Dropout, Lambda, Activation, BatchNormalization, LocallyConnected1D, Reshape\n",
    "import time\n",
    "\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = \"AKIAJIQ7JIXG4KRICKRA\"\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"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\"\n",
    "\n",
    "print(time.ctime(), 'Read files...')\n",
    "b = pd.read_csv('s3://daniglassbox/b.csv')\n",
    "d = pd.read_csv('s3://daniglassbox/d.csv', index_col=0, header=None, encoding='ISO-8859-1').T\n",
    "labels = pd.read_csv('s3://daniglassbox/labels.csv', index_col=0, header=None).T\n",
    "#Move in-situ 84 genes to the begining\n",
    "cols = list(b) + list(set(list(d)) - set(list(b)))\n",
    "d = d.loc[:,cols]\n",
    "d = d.div(d.sum(axis=1), axis=0)\n",
    "d.reset_index(drop=True, inplace=True)\n",
    "labels.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Sep 29 20:45:34 2018 Create true list of tuples\n",
      "Sat Sep 29 20:45:34 2018 Create false list of tuples\n",
      "Sat Sep 29 20:47:47 2018 Merging lists\n",
      "Sat Sep 29 20:47:47 2018 len(d_list): 11300\n",
      "Sat Sep 29 20:47:47 2018 Create train input arrays\n"
     ]
    }
   ],
   "source": [
    "#Create the true label pairs. Left: d-array, right: b-array \n",
    "#Labels start from 1 in the original file. They indicate a specific row in b table.\n",
    "print(time.ctime(),'Create true list of tuples')\n",
    "d['label'] = labels['label'] - 1\n",
    "d['one'] = 1\n",
    "d_true = list(zip(d.index, d.label, d.one))\n",
    "d = d.drop(['one', 'label'], 1)\n",
    "\n",
    "#Create the false label pairs\n",
    "print(time.ctime(), 'Create false list of tuples')\n",
    "a_list = [i for i in range(0,1297)] # d-array\n",
    "b_list = [j for j in range(0,3039)] # b-array\n",
    "d_prod = list(itertools.product(a_list, b_list))\n",
    "d_false = [x+(0,) for x in d_prod if x not in d_true]\n",
    "\n",
    "#Merge the two lists. Select 10003 samples from d and 1297 from b for training.\n",
    "print(time.ctime(), 'Merging lists')\n",
    "indicies = random.sample(range(len(d_false)), 10003)\n",
    "d_false1 = [d_false[i] for i in indicies]\n",
    "d_list = d_true + d_false1\n",
    "random.shuffle(d_list)\n",
    "print(time.ctime(), f'len(d_list): {len(d_list)}') #11300\n",
    "\n",
    "print(time.ctime(), 'Create train input arrays')\n",
    "X1_train = np.empty((10000, 84)) #Can create a test array using X1_test = np.empty((1300, 84))\n",
    "X2_train = np.empty((10000, 84))\n",
    "X3_train = np.empty((10000, 8840))\n",
    "y_train = np.empty((10000), dtype=int)\n",
    "batch=0\n",
    "for i in d_list[0:10000]:\n",
    "    try:\n",
    "        X1_train[batch] = b.iloc[i[1]]\n",
    "        X2_train[batch] = d.iloc[i[0]][0:84]\n",
    "        X3_train[batch] = d.iloc[i[0]][84:]\n",
    "        y_train[batch] = i[2]\n",
    "    except:\n",
    "        print('Exception in train.............', i)\n",
    "    finally:\n",
    "        batch = batch + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:21:46  Model build\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, 84)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            (None, 83)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 200)          17000       input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 200)          16800       input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 400)          0           dense_13[0][0]                   \n",
      "                                                                 dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 84)           33684       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 1)            85          dense_16[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 67,569\n",
      "Trainable params: 67,569\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Model build\n",
    "print(time.strftime(\"%H:%M:%S\"), ' Model build')\n",
    "\n",
    "#First input model\n",
    "input_a = Input(shape=(84,))\n",
    "dense_a = Dense(200, activation='softplus')(input_a)\n",
    "\n",
    "#Second input model\n",
    "input_b = Input(shape=(83,))\n",
    "dense_b = Dense(200, activation='softplus')(input_b)\n",
    "\n",
    "#Third input model\n",
    "input_c = Input(shape=(8840,))\n",
    "dense_c = Dense(50, activation='softplus')(input_c)\n",
    "drop_c = Dropout(0.2)(dense_c)\n",
    "\n",
    "concat_a = concatenate([dense_a, dense_b])\n",
    "dense_d = Dense(84, activation='softplus')(concat_a)\n",
    "drop_d = Dropout(0.2)(dense_d)\n",
    "\n",
    "concat_b = concatenate([drop_d, drop_c])\n",
    "dense_e = Dense(50, activation='softplus')(concat_b)\n",
    "dense_f = Dense(1, activation='sigmoid')(dense_d) # sigmoid\n",
    "model = Model(inputs=[input_a, input_b, input_c], outputs=[dense_f])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']) # binary_crossentropy\n",
    "model.save_weights('model.h5')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:22:10  Fit\n",
      "Sat Sep 29 21:22:26 2018 i: 0, val_acc average: 0.600766667748491, max: 0.7733333309491476\n",
      "Sat Sep 29 21:22:41 2018 i: 1, val_acc average: 0.55276666748027, max: 0.7453333377838135\n",
      "Sat Sep 29 21:22:57 2018 i: 2, val_acc average: 0.5977166690894713, max: 0.7846666673819224\n",
      "Sat Sep 29 21:23:12 2018 i: 3, val_acc average: 0.5503833354637027, max: 0.747000002861023\n",
      "Sat Sep 29 21:23:27 2018 i: 4, val_acc average: 0.606300001150618, max: 0.8509999980529149\n",
      "Sat Sep 29 21:23:42 2018 i: 5, val_acc average: 0.5569166679742436, max: 0.7829999993244807\n",
      "Sat Sep 29 21:23:57 2018 i: 6, val_acc average: 0.5516833351552488, max: 0.7140000025431316\n",
      "Sat Sep 29 21:24:12 2018 i: 7, val_acc average: 0.6102000008150934, max: 0.7983333299557368\n",
      "Sat Sep 29 21:24:27 2018 i: 8, val_acc average: 0.5506833345008395, max: 0.8416666636864344\n",
      "Sat Sep 29 21:24:42 2018 i: 9, val_acc average: 0.6408000022793809, max: 0.7683333287636439\n",
      "Sat Sep 29 21:24:58 2018 i: 10, val_acc average: 0.5739166682399809, max: 0.763333335518837\n",
      "Sat Sep 29 21:25:13 2018 i: 11, val_acc average: 0.5655166690237821, max: 0.7426666706800461\n",
      "Sat Sep 29 21:25:28 2018 i: 12, val_acc average: 0.5942833356869718, max: 0.7656666696071625\n",
      "Sat Sep 29 21:25:43 2018 i: 13, val_acc average: 0.6105333347556492, max: 0.790666667620341\n",
      "Sat Sep 29 21:25:58 2018 i: 14, val_acc average: 0.5293999999451141, max: 0.7533333341280619\n",
      "Sat Sep 29 21:26:13 2018 i: 15, val_acc average: 0.5396166678983717, max: 0.7270000030597051\n",
      "Sat Sep 29 21:26:28 2018 i: 16, val_acc average: 0.5964500014173488, max: 0.7646666626135509\n",
      "Sat Sep 29 21:26:44 2018 i: 17, val_acc average: 0.5127500000968576, max: 0.7503333340088526\n",
      "Sat Sep 29 21:26:59 2018 i: 18, val_acc average: 0.5253500001939635, max: 0.7530000001192093\n",
      "Sat Sep 29 21:27:14 2018 i: 19, val_acc average: 0.5285166679136454, max: 0.7320000032583872\n",
      "Sat Sep 29 21:27:29 2018 i: 20, val_acc average: 0.5591666675917804, max: 0.8023333350817362\n",
      "Sat Sep 29 21:27:44 2018 i: 21, val_acc average: 0.5952000014483928, max: 0.7936666667461395\n",
      "Sat Sep 29 21:27:59 2018 i: 22, val_acc average: 0.5595333356844884, max: 0.7326666702826817\n",
      "Sat Sep 29 21:28:14 2018 i: 23, val_acc average: 0.5701666674173127, max: 0.8359999934832255\n",
      "Sat Sep 29 21:28:29 2018 i: 24, val_acc average: 0.5188000003465763, max: 0.787666666507721\n",
      "Sat Sep 29 21:28:44 2018 i: 25, val_acc average: 0.5283833337513107, max: 0.6833333363135655\n",
      "Sat Sep 29 21:29:00 2018 i: 26, val_acc average: 0.5932333343227704, max: 0.7953333308299383\n",
      "Sat Sep 29 21:29:15 2018 i: 27, val_acc average: 0.5580000006283324, max: 0.7683333327372869\n",
      "Sat Sep 29 21:29:31 2018 i: 28, val_acc average: 0.6036666684597731, max: 0.7546666671832403\n",
      "Sat Sep 29 21:29:46 2018 i: 29, val_acc average: 0.6222166686753432, max: 0.770333331823349\n",
      "Sat Sep 29 21:30:02 2018 i: 30, val_acc average: 0.5181833349230389, max: 0.6533333351214726\n",
      "Sat Sep 29 21:30:17 2018 i: 31, val_acc average: 0.6442333357036114, max: 0.7839999983708064\n",
      "Sat Sep 29 21:30:33 2018 i: 32, val_acc average: 0.616733334613964, max: 0.8286666631698608\n",
      "Sat Sep 29 21:30:48 2018 i: 33, val_acc average: 0.5893833342629174, max: 0.7793333311875661\n",
      "Sat Sep 29 21:31:03 2018 i: 34, val_acc average: 0.5875333341024815, max: 0.7806666572888692\n",
      "Sat Sep 29 21:31:18 2018 i: 35, val_acc average: 0.6146500026962409, max: 0.7820000022649765\n",
      "Sat Sep 29 21:31:33 2018 i: 36, val_acc average: 0.5263000015790263, max: 0.6993333329757054\n",
      "Sat Sep 29 21:31:48 2018 i: 37, val_acc average: 0.5280666676412026, max: 0.7533333351214727\n",
      "Sat Sep 29 21:32:03 2018 i: 38, val_acc average: 0.5390333351958543, max: 0.7913333356380463\n",
      "Sat Sep 29 21:32:18 2018 i: 39, val_acc average: 0.5964666667580605, max: 0.8576666623353958\n",
      "Sat Sep 29 21:32:33 2018 i: 40, val_acc average: 0.5760833355939636, max: 0.7323333382606506\n",
      "Sat Sep 29 21:32:48 2018 i: 41, val_acc average: 0.5929000007609526, max: 0.7763333251078923\n",
      "Sat Sep 29 21:33:04 2018 i: 42, val_acc average: 0.594833334516734, max: 0.8043333301941554\n",
      "Sat Sep 29 21:33:19 2018 i: 43, val_acc average: 0.5863500008483727, max: 0.7616666634877522\n",
      "Sat Sep 29 21:33:34 2018 i: 44, val_acc average: 0.5574000012346854, max: 0.7726666659116745\n",
      "Sat Sep 29 21:33:49 2018 i: 45, val_acc average: 0.5401000018728276, max: 0.7116666704416275\n",
      "Sat Sep 29 21:34:04 2018 i: 46, val_acc average: 0.5798000018888464, max: 0.7646666705608368\n",
      "Sat Sep 29 21:34:19 2018 i: 47, val_acc average: 0.5853333354430894, max: 0.7626666675011317\n",
      "Sat Sep 29 21:34:34 2018 i: 48, val_acc average: 0.56970000153097, max: 0.7616666664679845\n",
      "Sat Sep 29 21:34:49 2018 i: 49, val_acc average: 0.5897833344029884, max: 0.766333332657814\n",
      "Sat Sep 29 21:35:04 2018 i: 50, val_acc average: 0.594433335668097, max: 0.7983333319425583\n",
      "Sat Sep 29 21:35:20 2018 i: 51, val_acc average: 0.5205333345072964, max: 0.73900000055631\n",
      "Sat Sep 29 21:35:35 2018 i: 52, val_acc average: 0.5770500017019609, max: 0.7550000021855037\n",
      "Sat Sep 29 21:35:50 2018 i: 53, val_acc average: 0.5836333354065816, max: 0.7466666688521703\n",
      "Sat Sep 29 21:36:05 2018 i: 54, val_acc average: 0.5604500013589859, max: 0.734666665395101\n",
      "Sat Sep 29 21:36:20 2018 i: 55, val_acc average: 0.5824166687143345, max: 0.7726666669050852\n",
      "Sat Sep 29 21:36:35 2018 i: 56, val_acc average: 0.5694666676285366, max: 0.7780000001192093\n",
      "Sat Sep 29 21:36:50 2018 i: 57, val_acc average: 0.6125333344191314, max: 0.7706666628519694\n",
      "Sat Sep 29 21:37:05 2018 i: 58, val_acc average: 0.5730833345713715, max: 0.7529999981323878\n",
      "Sat Sep 29 21:37:20 2018 i: 59, val_acc average: 0.597416668108975, max: 0.7946666677792867\n",
      "Sat Sep 29 21:37:35 2018 i: 60, val_acc average: 0.5314833351473014, max: 0.6650000035762786\n",
      "Sat Sep 29 21:37:50 2018 i: 61, val_acc average: 0.601016668577989, max: 0.7819999982913335\n",
      "Sat Sep 29 21:38:05 2018 i: 62, val_acc average: 0.5463333334463337, max: 0.8229999969402949\n",
      "Sat Sep 29 21:38:21 2018 i: 63, val_acc average: 0.5445666677815219, max: 0.7506666660308838\n",
      "Sat Sep 29 21:38:36 2018 i: 64, val_acc average: 0.5723500017945965, max: 0.7719999998807907\n",
      "Sat Sep 29 21:38:51 2018 i: 65, val_acc average: 0.5780333352833986, max: 0.6873333334922791\n",
      "Sat Sep 29 21:39:06 2018 i: 66, val_acc average: 0.5738666688216231, max: 0.7500000019868215\n",
      "Sat Sep 29 21:39:21 2018 i: 67, val_acc average: 0.5582000000588596, max: 0.8106666594743729\n",
      "Sat Sep 29 21:39:36 2018 i: 68, val_acc average: 0.5367666677292436, max: 0.7516666650772095\n",
      "Sat Sep 29 21:39:51 2018 i: 69, val_acc average: 0.55370000085483, max: 0.7480000038941701\n",
      "Sat Sep 29 21:40:06 2018 i: 70, val_acc average: 0.5814833342532316, max: 0.7576666633288066\n",
      "Sat Sep 29 21:40:21 2018 i: 71, val_acc average: 0.5798666681349277, max: 0.7830000003178914\n",
      "Sat Sep 29 21:40:37 2018 i: 72, val_acc average: 0.5650500010078152, max: 0.8003333330154419\n",
      "Sat Sep 29 21:40:52 2018 i: 73, val_acc average: 0.5629166684175532, max: 0.7276666690905889\n",
      "Sat Sep 29 21:41:07 2018 i: 74, val_acc average: 0.5989500016036133, max: 0.8159999946753184\n",
      "Sat Sep 29 21:41:22 2018 i: 75, val_acc average: 0.5970333350511889, max: 0.8479999969402949\n",
      "Sat Sep 29 21:41:37 2018 i: 76, val_acc average: 0.5805000010194878, max: 0.7699999988079071\n",
      "Sat Sep 29 21:41:52 2018 i: 77, val_acc average: 0.5539333340028922, max: 0.7966666638851165\n",
      "Sat Sep 29 21:42:07 2018 i: 78, val_acc average: 0.6227333364139002, max: 0.7610000014305115\n",
      "Sat Sep 29 21:42:22 2018 i: 79, val_acc average: 0.5904166680636506, max: 0.8076666633288065\n",
      "Sat Sep 29 21:42:38 2018 i: 80, val_acc average: 0.5636333346491058, max: 0.8126666605472564\n",
      "Sat Sep 29 21:42:53 2018 i: 81, val_acc average: 0.5963000006694347, max: 0.7706666638453802\n",
      "Sat Sep 29 21:43:08 2018 i: 82, val_acc average: 0.6297833344340324, max: 0.8209999928871791\n",
      "Sat Sep 29 21:43:23 2018 i: 83, val_acc average: 0.5699500012025237, max: 0.7796666671832403\n"
     ]
    }
   ],
   "source": [
    "print(time.strftime(\"%H:%M:%S\"), ' Fit')\n",
    "\n",
    "val_acc=np.empty((84,2))\n",
    "for i in range(84):\n",
    "    model.load_weights('model.h5')\n",
    "    X2_temp = np.delete(X2_train, i, axis=1)\n",
    "    #tbCallBack = keras.callbacks.TensorBoard(log_dir='.', histogram_freq=0, write_graph=True, write_images=True)\n",
    "    history = model.fit(x=[X1_train, X2_temp, X3_train],\n",
    "                        y=y_train,\n",
    "                        batch_size=50,\n",
    "                        epochs=20,\n",
    "                        verbose=0,\n",
    "                        validation_split=0.3,\n",
    "                        class_weight={0:1, 1:10}) #, use_multiprocessing=True, workers=8) #, callbacks=[tbCallBack])\n",
    "    val_acc[i,0] = np.average(history.history['val_acc'])\n",
    "    val_acc[i,1] = np.max(history.history['val_acc'])\n",
    "    print(time.ctime(), f'i: {i}, val_acc average: {val_acc[i,0]}, max: {val_acc[i,1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ln: cannot remove ‘/usr/bin/nvidia-smi’: Permission denied\n",
      "Requirement already satisfied: gputil in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (1.3.0)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from gputil) (1.15.1)\n",
      "\u001b[31mkeras 2.2.2 has requirement keras-applications==1.0.4, but you'll have keras-applications 1.0.5 which is incompatible.\u001b[0m\n",
      "\u001b[31mkeras 2.2.2 has requirement keras-preprocessing==1.0.2, but you'll have keras-preprocessing 1.0.3 which is incompatible.\u001b[0m\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: psutil in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (5.4.5)\n",
      "\u001b[31mkeras 2.2.2 has requirement keras-applications==1.0.4, but you'll have keras-applications 1.0.5 which is incompatible.\u001b[0m\n",
      "\u001b[31mkeras 2.2.2 has requirement keras-preprocessing==1.0.2, but you'll have keras-preprocessing 1.0.3 which is incompatible.\u001b[0m\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: humanize in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (0.5.1)\n",
      "\u001b[31mkeras 2.2.2 has requirement keras-applications==1.0.4, but you'll have keras-applications 1.0.5 which is incompatible.\u001b[0m\n",
      "\u001b[31mkeras 2.2.2 has requirement keras-preprocessing==1.0.2, but you'll have keras-preprocessing 1.0.3 which is incompatible.\u001b[0m\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Gen RAM Free: 60.0 GB  | Proc size: 3.2 GB\n",
      "GPU RAM Free: 734MB | Used: 15418MB | Util  95% | Total 16152MB\n"
     ]
    }
   ],
   "source": [
    "# memory footprint support libraries/code\n",
    "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
    "!pip install gputil\n",
    "!pip install psutil\n",
    "!pip install humanize\n",
    "import psutil\n",
    "import humanize\n",
    "import os\n",
    "import GPUtil as GPU\n",
    "GPUs = GPU.getGPUs()\n",
    "# XXX: only one GPU on Colab and isn’t guaranteed\n",
    "gpu = GPUs[0]\n",
    "def printm():\n",
    " process = psutil.Process(os.getpid())\n",
    " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
    " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
    "printm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uninstalling tensorflow-1.8.0:\n",
      "  Successfully uninstalled tensorflow-1.8.0\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall tensorflow -y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
