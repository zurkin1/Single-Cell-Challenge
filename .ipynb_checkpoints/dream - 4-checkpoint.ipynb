{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using class generator.\n",
    "- Trying different models.\n",
    "- Output layer activation is sigmoid. Metrics is binary_crossentropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate locations of 1297 cells\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import matthews_corrcoef as mcc\n",
    "\n",
    "bdtnp = pd.read_csv('binarized_bdtnp.csv', squeeze=True)\n",
    "dge = pd.read_csv('dge_binarized_distMap.csv', squeeze=True)\n",
    "#print(dge.shape) #(84, 1297)\n",
    "#bdtnp.shape #(3039, 84)\n",
    "#print(dge['GTACTAATTACN_2'].dot(bdtnp.iloc[0])) #15\n",
    "#print(dge['GTACTAATTACN_2'].dtypes) #dtype('int64')\n",
    "#print(dge[col].shape) #(84,)\n",
    "#dge[col] * bdtnp\n",
    "\n",
    "ind = {}\n",
    "for col in dge:\n",
    "    ind[col] = np.argmax(list(mcc(bdtnp.iloc[i], dge[col]) for i in range(3039)))\n",
    "    #ind[col] = max(dge[col] * bdtnp.iloc[i]) #Test\n",
    "    print(ind[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pydot\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Embedding, concatenate, Flatten, Dropout, Lambda, Activation, BatchNormalization, LocallyConnected1D, Reshape\n",
    "from keras.utils import plot_model\n",
    "import time\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "b = pd.read_csv('bdtnp.csv')\n",
    "#Changes 'na' to 'naa' and 'nan' to 'nana'\n",
    "d = pd.read_csv('dge_raw.csv', index_col=0, header=None, encoding='ISO-8859-1').T\n",
    "labels = pd.read_csv('labels.csv', index_col=0, header=None).T\n",
    "#Move in-situ 84 genes to the begining\n",
    "cols = list(b) + list(set(list(d)) - set(list(b)))\n",
    "d = d.loc[:,cols]\n",
    "d = d.div(d.sum(axis=1), axis=0)\n",
    "d.reset_index(drop=True, inplace=True)\n",
    "labels.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11300"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create the true label pairs. Left: d-array, right: b-array \n",
    "#Labels start from 1 in the original file. They indicate a specific row in b table.\n",
    "d['label'] = labels['label'] - 1\n",
    "d['one'] = 1\n",
    "d_true = list(zip(d.index, d.label, d.one))\n",
    "d = d.drop(['one', 'label'], 1)\n",
    "\n",
    "#Create the false label pairs\n",
    "a_list = [i for i in range(0,1297)] # d-array\n",
    "b_list = [j for j in range(0,3039)] # b-array\n",
    "d_prod = list(itertools.product(a_list, b_list))\n",
    "d_false = [x+(0,) for x in d_prod if x not in d_true]\n",
    "#dge.ix[:,0:-1]\n",
    "#dge[dge.columns[1:-1]]\n",
    "#dge.iloc[:,0:-1]\n",
    "#bdtnp['label'] = 0 #bdtnp.index + 1\n",
    "#dge['label'] = 0\n",
    "#dge_false = pd.merge(dge, bdtnp, on='label')\n",
    "\n",
    "#Merge the two lists. Select 10003 samples from d and 1297 from b for training.\n",
    "indicies = random.sample(range(len(d_false)), 10003)\n",
    "d_false1 = [d_false[i] for i in indicies]\n",
    "d_list = d_true + d_false1\n",
    "random.shuffle(d_list)\n",
    "\n",
    "len(d_list) #11300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "#Output of generator should be a tuple `(x, y, sample_weight)` or `(x, y)`.\n",
    "class generate_array(keras.utils.Sequence):\n",
    "    def __init__(self, pairs_set, batch_s):\n",
    "        self.pairs = pairs_set\n",
    "        self.batch_size = batch_s\n",
    "    \n",
    "    #Return the maximume number of batches\n",
    "    #Dataset size is 11300. For a batch_size=100 we need 113 iterations of 100.\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.pairs) / float(self.batch_size)))\n",
    "    \n",
    "    #Returns the batch #idx\n",
    "    def __getitem__(self,idx):\n",
    "        X1 = np.empty((self.batch_size, 84, 2))\n",
    "        X2 = np.empty((self.batch_size, 8840))\n",
    "        y = np.empty((self.batch_size), dtype=int)\n",
    "        batch = 0\n",
    "        for i in self.pairs[self.batch_size*idx : self.batch_size*(idx+1)]:\n",
    "            try:\n",
    "                b_row = b.iloc[i[1]]\n",
    "                d_row_1 = d.iloc[i[0]][0:84]\n",
    "                d_row_2 = d.iloc[i[0]][84:]\n",
    "            except:\n",
    "                print('Exception.............', i)\n",
    "                continue\n",
    "            X1[batch] = np.column_stack((b_row, d_row_1))\n",
    "            X2[batch] = d_row_2\n",
    "            y[batch] = i[2]\n",
    "            batch = batch + 1\n",
    "        return([X1, X2], y)\n",
    "\n",
    "myg = generate_array(d_list, 100)\n",
    "print(myg.__getitem__(0)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "#Output of generator should be a tuple `(x, y, sample_weight)` or `(x, y)`.\n",
    "class generate_array(keras.utils.Sequence):\n",
    "    def __init__(self, pairs_set, batch_s):\n",
    "        self.pairs = pairs_set\n",
    "        self.batch_size = batch_s\n",
    "    \n",
    "    #Return the maximume number of batches\n",
    "    #Dataset size is 11300. For a batch_size=100 we need 113 iterations of 100.\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.pairs) / float(self.batch_size)))\n",
    "    \n",
    "    #Returns the batch #idx\n",
    "    def __getitem__(self,idx):\n",
    "        X1 = np.empty((self.batch_size, 84))\n",
    "        X2 = np.empty((self.batch_size, 84))\n",
    "        X3 = np.empty((self.batch_size, 8840))\n",
    "        y = np.empty((self.batch_size), dtype=int)\n",
    "        batch = 0\n",
    "        for i in self.pairs[self.batch_size*idx : self.batch_size*(idx+1)]:\n",
    "            try:\n",
    "                b_row = b.iloc[i[1]]\n",
    "                d_row_1 = d.iloc[i[0]][0:84]\n",
    "                d_row_2 = d.iloc[i[0]][84:]\n",
    "            except:\n",
    "                print('Exception.............', i)\n",
    "                continue\n",
    "            X1[batch] = b_row\n",
    "            X2[batch] = d_row_1\n",
    "            X3[batch] = d_row_2\n",
    "            y[batch] = i[2]\n",
    "            batch = batch + 1\n",
    "        return([X1, X2, X3], y)\n",
    "\n",
    "myg = generate_array(d_list, 100)\n",
    "print(myg.__getitem__(0)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22:13:15  Model build\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, 84, 2)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d_2 (LocallyC (None, 84, 1)        252         input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            (None, 84)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 84)           0           locally_connected1d_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 200)          17000       input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 284)          0           flatten_2[0][0]                  \n",
      "                                                                 dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 84)           23940       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 1)            85          dense_15[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 41,277\n",
      "Trainable params: 41,277\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Model build\n",
    "print(time.strftime(\"%H:%M:%S\"), ' Model build')\n",
    "\n",
    "#First input model\n",
    "input_a = Input(shape=(84,2))\n",
    "local_con_a = LocallyConnected1D(1, 1, activation='softplus')(input_a)\n",
    "flat_a = Flatten()(local_con_a)\n",
    "\n",
    "#Second input model\n",
    "input_b = Input(shape=(84,))\n",
    "dense_b = Dense(200, activation='softplus')(input_b)\n",
    "\n",
    "concat = concatenate([flat_a, dense_b])\n",
    "dense_c = Dense(84, activation='softplus')(concat)\n",
    "dense_d = Dense(1, activation='softplus')(dense_c)\n",
    "model = Model(inputs=[input_a, input_b], outputs=[dense_d])\n",
    "model.compile(optimizer='adam', loss='mae', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "#plot_model(model, to_file='my_model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22:27:46  Model build\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_29 (InputLayer)           (None, 84)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_30 (InputLayer)           (None, 84)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_63 (Dense)                (None, 200)          17000       input_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_64 (Dense)                (None, 200)          17000       input_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 400)          0           dense_63[0][0]                   \n",
      "                                                                 dense_64[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_31 (InputLayer)           (None, 8840)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_66 (Dense)                (None, 100)          40100       concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_65 (Dense)                (None, 50)           442050      input_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 150)          0           dense_66[0][0]                   \n",
      "                                                                 dense_65[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_67 (Dense)                (None, 50)           7550        concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_68 (Dense)                (None, 1)            51          dense_67[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 523,751\n",
      "Trainable params: 523,751\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Model build\n",
    "print(time.strftime(\"%H:%M:%S\"), ' Model build')\n",
    "\n",
    "#First input model\n",
    "input_a = Input(shape=(84,))\n",
    "dense_a = Dense(200, activation='softplus')(input_a)\n",
    "\n",
    "#Second input model\n",
    "input_b = Input(shape=(84,))\n",
    "dense_b = Dense(200, activation='softplus')(input_b)\n",
    "\n",
    "#Third input model\n",
    "input_c = Input(shape=(8840,))\n",
    "dense_c = Dense(50, activation='softplus')(input_c)\n",
    "\n",
    "concat_a = concatenate([dense_a, dense_b])\n",
    "dense_d = Dense(100, activation='softplus')(concat_a)\n",
    "concat_b = concatenate([dense_d, dense_c])\n",
    "dense_e = Dense(50, activation='softplus')(concat_b)\n",
    "dense_f = Dense(1, activation='sigmoid')(dense_e)\n",
    "model = Model(inputs=[input_a, input_b, input_c], outputs=[dense_f])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "#plot_model(model, to_file='my_model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(time.strftime(\"%H:%M:%S\"), ' Fit')\n",
    "tbCallBack = keras.callbacks.TensorBoard(log_dir='.', histogram_freq=0, write_graph=True, write_images=True)\n",
    "history = model.fit_generator(generate_array(d_list[0:10000], 50),\n",
    "                              steps_per_epoch=200,\n",
    "                              epochs=20,\n",
    "                              verbose=2,\n",
    "                              validation_data=generate_array(d_list[10000:13000],50),\n",
    "                              class_weight={0:1, 1:10}) #, use_multiprocessing=True, workers=8) #, callbacks=[tbCallBack])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(x[0],x[1]) for x in d_list[10000:10010]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
