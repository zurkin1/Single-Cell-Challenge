{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Moving sampling of data to pairs.\n",
    "Todo\n",
    "- Check convergence.\n",
    "- Run on Linux.\n",
    "- Compare runs of 80 and in situ genes.\n",
    "- Add dropouts.\n",
    "- Select the best 60 genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Embedding, Concatenate, Flatten, Dropout, Lambda, Activation, BatchNormalization\n",
    "import time\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "b = pd.read_csv('bdtnp.csv')\n",
    "d = pd.read_csv('dge_raw.csv', index_col=0, header=None, encoding='ISO-8859-1').T\n",
    "labels = pd.read_csv('labels.csv', index_col=0, header=None).T\n",
    "d = d.div(d.sum(axis=1), axis=0)\n",
    "#Labels start from 1 in the original file. They indicate a specific row in b table.\n",
    "d['label'] = labels['label'] - 1\n",
    "d['one'] = 1\n",
    "\n",
    "#Create the true label pairs. Left: d-array, right: b-array \n",
    "d_true = list(zip(d.index, d.label, d.one))\n",
    "d = d.drop('one', 1)\n",
    "d = d.drop('label', 1)\n",
    "\n",
    "#Create the false label pairs\n",
    "a_list = [i for i in range(0,1297)] # d-array\n",
    "b_list = [j for j in range(0,3039)] # b-array\n",
    "d_prod = list(itertools.product(a_list, b_list))\n",
    "d_false = [x+(0,) for x in d_prod if x not in d_true]\n",
    "#dge.ix[:,0:-1]\n",
    "#dge[dge.columns[1:-1]]\n",
    "#dge.iloc[:,0:-1]\n",
    "#bdtnp['label'] = 0 #bdtnp.index + 1\n",
    "#dge['label'] = 0\n",
    "#dge_false = pd.merge(dge, bdtnp, on='label')\n",
    "\n",
    "#Merge the two lists\n",
    "indicies = random.sample(range(len(d_false)), 10003)\n",
    "d_false1 = [d_false[i] for i in indicies]\n",
    "d_list = d_true + d_false1\n",
    "random.shuffle(d_list)\n",
    "\n",
    "len(d_list) #11300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 9008)\n",
      "[0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "#Output of generator should be a tuple `(x, y, sample_weight)` or `(x, y)`.\n",
    "def generate_array(batch_size=100):\n",
    "    while True:\n",
    "        X = np.empty((batch_size, 9008))\n",
    "        y = np.empty((batch_size), dtype=int)\n",
    "        #Dataset size is 11300. For a batch_size=100 we need 113 iterations of 100.\n",
    "        for i in range(113):\n",
    "            batch = 0\n",
    "            for j in d_list[i * batch_size : (i+1) * batch_size]:\n",
    "                try:\n",
    "                    b_row = b.iloc[j[1]]\n",
    "                    d_row = d.iloc[j[0]]\n",
    "                except:\n",
    "                    print('Exception.............', j)\n",
    "                    continue\n",
    "                row = b_row.append(d_row)\n",
    "                X[batch] = row\n",
    "                y[batch] = j[2]\n",
    "                batch = batch + 1\n",
    "            yield(X,y)\n",
    "\n",
    "myg = generate_array()\n",
    "for i in myg:\n",
    "    print(i[0].shape)\n",
    "    print(i[1])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "09:51:04  Model build\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 84)                756756    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 85        \n",
      "=================================================================\n",
      "Total params: 756,841\n",
      "Trainable params: 756,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Model build\n",
    "print(time.strftime(\"%H:%M:%S\"), ' Model build')\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(84, activation='relu', input_dim=9008)) #9008\n",
    "model.add(Dense(1, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='mae', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "09:51:07  Fit\n",
      "Epoch 1/5\n",
      "  5/113 [>.............................]Exception............. (1297, 757, 1)0\n",
      "113/113 [==============================] - 11s 97ms/step - loss: 5.1240 - acc: 0.1132 6s - loss: 4.3974 - acc: 0.113 - ETA: 5s - loss: \n",
      "Epoch 2/5\n",
      "Exception............. (1297, 757, 1)..] - ETA: 9s - loss: 6.8850 - acc: 0.1000\n",
      "113/113 [==============================] - 11s 96ms/step - loss: 5.9350 - acc: 0.1142\n",
      "Epoch 3/5\n",
      "  5/113 [>.............................] - ETA: 10s - loss: 6.4720 - acc: 0.1140Exception............. (1297, 757, 1)\n",
      "113/113 [==============================] - 11s 99ms/step - loss: 4.5954 - acc: 0.1121: 10s - loss: 4.5475  - ETA: 8s - loss: 4. - ETA: 6s - loss: 4.2665 - acc - ETA - ETA: 2s - loss:\n",
      "Epoch 4/5\n",
      "  6/113 [>.............................] - ETA: 11s - loss: 2.2250 - acc: 0.1050Exception............. (1297, 757, 1)\n",
      "113/113 [==============================] - 11s 102ms/step - loss: 4.3806 - acc: 0.11502s - loss: 4.0953 - acc: 0.11 - ETA: 2s - loss: 4.0681 - a - ETA: 1s - loss: 4.0375 - \n",
      "Epoch 5/5\n",
      "  5/113 [>.............................] - ETA: 11s - loss: 8.8720 - acc: 0.1080 Exception............. (1297, 757, 1)\n",
      "113/113 [==============================] - 11s 95ms/step - loss: 5.5479 - acc: 0.1130 0s - loss: 5.6527 - acc: 0.\n"
     ]
    }
   ],
   "source": [
    "print(time.strftime(\"%H:%M:%S\"), ' Fit')\n",
    "tbCallBack = keras.callbacks.TensorBoard(log_dir='.', histogram_freq=0, write_graph=True, write_images=True)\n",
    "history = model.fit_generator(generate_array(),\n",
    "                              steps_per_epoch=113,\n",
    "                              epochs=5,\n",
    "                              verbose=1,\n",
    "                              class_weight={0:1, 1:10}) #, callbacks=[tbCallBack])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
