{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(tf.test.is_built_with_cuda())\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    devices = sess.list_devices()\n",
    "    print(devices)\n",
    "\n",
    "#watch -n 2 nvidia-smi\n",
    "#watch -d -n 0.5 nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from itertools import combinations as cs\n",
    "import sys\n",
    "import time\n",
    "\n",
    "num_situ = 20\n",
    "batch_size = 100 # 100\n",
    "two_list = [[[2**x] for x in range(0,num_situ)] for j in range(batch_size)]\n",
    "glist = ['danr', 'CG14427', 'dan', 'CG43394', 'ImpL2', 'Nek2', 'CG8147', 'Ama', 'Btk29A', 'trn', 'numb', 'prd', 'brk', 'tsh', 'pxb', 'dpn', 'ftz', 'Kr', 'h', 'eve', 'Traf4', 'run', 'Blimp-1', 'lok', 'kni', 'tkv', 'MESR3', 'odd', 'noc', 'nub', 'Ilp4', 'aay', 'twi', 'bmm', 'hb', 'toc', 'rho', 'CG10479', 'gt', 'gk', 'apt', 'D', 'sna', 'NetA', 'Mdr49', 'fj', 'Mes2', 'CG11208', 'Doc2', 'bun', 'tll', 'Cyp310a1', 'Doc3', 'htl', 'Esp', 'bowl', 'oc', 'ImpE2', 'CG17724', 'fkh', 'edl', 'ems', 'zen2', 'CG17786', 'zen', 'disco', 'Dfd', 'mfas', 'knrl', 'Ance', 'croc', 'rau', 'cnc', 'exex', 'cad', 'Antp', 'erm', 'ken', 'peb', 'srp', 'E(spl)m5-HLH', 'CenG1A', 'zfh1', 'hkb']\n",
    "bdtnp_bin = pd.read_csv('../../data/binarized_bdtnp.csv')\n",
    "bdtnp = bdtnp_bin.values.astype(np.int32)\n",
    "print(time.ctime())\n",
    "\n",
    "def generator():\n",
    "    for tup in cs(glist, num_situ): #sequence:\n",
    "        yield bdtnp_bin[np.reshape(tup, -1)].values.astype(np.int32)\n",
    "\n",
    "dataset = tf.data.Dataset().from_generator(generator,\n",
    "                                   output_types= tf.int32, \n",
    "                                   output_shapes=(tf.TensorShape([3039, num_situ]))).batch(batch_size).prefetch(4000000) # 4000000\n",
    "dataset = dataset.apply(tf.contrib.data.prefetch_to_device('/gpu:0')) #tf.data.experimental.prefetch_to_device\n",
    "iter = dataset.make_initializable_iterator()\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "    Y = tf.placeholder(tf.int32, shape=(batch_size, num_situ,1))\n",
    "    a = tf.Variable(tf.constant(0))\n",
    "    init = tf.global_variables_initializer()\n",
    "    # Track both the loop index and summation in a tuple in the form (index, summation)\n",
    "    index_max = (tf.constant(1), a)\n",
    "    \n",
    "    #The loop condition\n",
    "    def condition(index, all_max):\n",
    "        return tf.less(index, 100)\n",
    "\n",
    "    #Use a print version that works on Jupyter notebook as well.\n",
    "    def tf_print(op, tensors, message=None):\n",
    "        def print_message(x):\n",
    "            if(int(x) % 10 == 0):\n",
    "                sys.stdout.write(\"%s\\n\" % x) #message,\n",
    "            return x\n",
    "\n",
    "        prints = [tf.py_func(print_message, [tensor], tensor.dtype) for tensor in tensors]\n",
    "        with tf.control_dependencies(prints):\n",
    "            op = tf.identity(op)\n",
    "        return op\n",
    "\n",
    "    # The loop body, this will return a result tuple in the same form (index, summation)\n",
    "    def body(index, all_max):\n",
    "        #Y = tf.reshape(tf.tile( tf.constant([1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536, 131072, 262144, 524288], tf.int32),\n",
    "        #                        tf.constant([batch_size])), \n",
    "        #              (batch_size, num_situ,1))\n",
    "        print_op = tf_print(index + 1, [index]) #Instead of tf.Print.\n",
    "        X = iter.get_next()\n",
    "        #Code binary sequences as integers in range [0,2**20].\n",
    "        product = tf.matmul(X, Y) # product.shape == (10, 3039, 1)\n",
    "        #Move to vector\n",
    "        un_2 = tf.to_int32(tf.squeeze(product)) # un_2.shape == (10, 3039)\n",
    "        \n",
    "        #Count appearance of the same unique number in different rows using one-hot encoding.\n",
    "        one_hot_t = tf.one_hot(un_2, 512) # one_hot_t.shape == (10, 3039, 639) #639, y_vals\n",
    "        count_all = tf.reduce_sum(one_hot_t, axis=1) # count_all.shape == (10, 3039)\n",
    "        count_ones = tf.ones_like(count_all)\n",
    "        count_zeros = tf.zeros_like(count_all)\n",
    "        exact_count = tf.where(tf.equal(count_all, 1.), count_ones, count_zeros)\n",
    "        sum_count = tf.reduce_sum(exact_count, axis=1) # sum_count.shape == (10,)\n",
    "        \n",
    "        \"\"\"\n",
    "        #Using unsorted_segment_sum instead of bincount in order to support GPU.\n",
    "        #From documentation of bincount: if weights are non-None, then index i of the output stores the sum of the value in weights at each\n",
    "        #index where the corresponding value in arr is i.\n",
    "        #Since unsorted_segment_sum does not support batched, we add to each segment_id num_segments*row_index.\n",
    "        bins = 2**20\n",
    "        _ones = tf.ones_like(un_2)\n",
    "        num_rows = batch_size\n",
    "        rows_idx = tf.range(num_rows) # (10,)\n",
    "        segment_ids_per_row = un_2 + bins * tf.expand_dims(rows_idx, axis=1) # (10, 3039)\n",
    "        seg_sums = tf.unsorted_segment_sum(_ones, segment_ids_per_row, bins * num_rows)  # (2^20 * 10,)\n",
    "        #count_all = tf.transpose(tf.unsorted_segment_sum(tf.transpose(_ones), tf.transpose(un_2), bins)) # count_all.shape == (300,)\n",
    "        count_all = tf.reshape(seg_sums, [-1, bins]) # (10, 2^20)\n",
    "        _zero_bins = tf.zeros_like(count_all)\n",
    "        _one_bins = tf.ones_like(count_all)\n",
    "        exact_count = tf.where(tf.equal(count_all, 1), _one_bins, _zero_bins) # (10, 2^20)\n",
    "        sum_count = tf.reduce_sum(exact_count, axis=1) # sum_count.shape == (10,)\n",
    "        \"\"\"\n",
    "        with tf.control_dependencies([print_op]):\n",
    "            return tf.add(index, 1), tf.to_int32(tf.reduce_max(sum_count)) # tf.maximum(tf.reduce_max(sum_count), all_max)\n",
    "\n",
    "    wh_loop = tf.while_loop(condition, body, index_max)[1]\n",
    "\n",
    "with tf.Session(config=tf.ConfigProto(log_device_placement=True, allow_soft_placement=True)) as sess:\n",
    "    sess.run(init)\n",
    "    sess.run(iter.initializer)\n",
    "    result = sess.run(wh_loop, feed_dict={Y: two_list})\n",
    "\n",
    "print(time.ctime(), f'Best result: {result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
