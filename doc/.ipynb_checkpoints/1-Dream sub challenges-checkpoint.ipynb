{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dream Challenge Solution Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"toc\"></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook handles the 60, 40 and 20 genes sub-challenges. It uses a combination of two models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Model - Max(MCC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- First model is based on calculating MAX(MCC) using only 60(40 or 20) genes as opposed to using 84 genes.\n",
    "- Calculating of MCC is done using matrix multiplication.\n",
    "- A list of 'candidates' for locations is assembeled using the MAX(MCC) calculation.\n",
    "- This list is then refined using the second model.\n",
    "- In the case of 60 genes, MAX(MCC) gives a very good results (location prediction). The second model is hardly needed in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Model - ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The second model is a simple ANN to forecast BTDNP sequences given a DGE sequence.\n",
    "- Input: a row from binarized DGE.\n",
    "- Output: a prediction for a row from binarized BDTNP (the correct location).\n",
    "- It is used to 'correct' the MAX(MCC) results.\n",
    "- The advatage of this model is being able to predict correct gene patterns (as opposed to just maximizing MCC, i.e. location).\n",
    "- The model is heavily relying on a correct selction of subsets of 60/40/20 genes. Please see the Appendix on gene selection.\n",
    "- In the case of 20 genes - it is the only model used since the MAX(MCC) is totally off."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining The Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- How to combine the two models?\n",
    "- We have 10 possibilities (locations) for each cell. We let Max(MCC) propose candidates and then 'correct' the result and select the best candidates using the ANN model.\n",
    "- If Max(MCC) propose less than 10 results - it means these are very strong results, and we keep them. Otherwise we ignore the results and use only ANN model.\n",
    "- A manual calibration was done to decide how many candidates we want from the Max(MCC) model. This means selecting the 'cutoff' value of MCC such that we take all locations above this value as a candidate for a location.\n",
    "    - In case of 60 genes trial and error gives an optimal selection of the 2'nd MCC score as a cutoff.\n",
    "    - In case of 40 genese optimal solution is taking the top 2'nd score using Max(MCC) as a cutoff.\n",
    "    - In case of 20 genes all 10 locations are decided using ANN (we are not using the Max(MCC) model at all.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Make sure you installed Python 3 with SKLearn (we used Anaconda), Tensorflow and Keras.\n",
    "- Just run the following cells one by one.\n",
    "- This notebook has to be run three times - for the 60, 40 and 20 genes sub-challenge.\n",
    "- Manual configuration:\n",
    "    - In the following cell - configure num_situ as the number of in-situ genes (sub-challenge) to use. Either 60, 40 or 20."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build an ANN Model for DGE->BDTNP Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import pairwise_distances_argmin\n",
    "import keras\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Dense, Embedding, concatenate, Flatten, Dropout, Lambda, Activation, BatchNormalization, LocallyConnected1D, Reshape, AlphaDropout, Conv1D, MaxPooling1D\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import time\n",
    "import sys\n",
    "\n",
    "######################################################\n",
    "# This is the only parameter you need to configure.  #\n",
    "# It has to be run three times (60, 40 and 20 genes. #\n",
    "######################################################\n",
    "num_situ = 60\n",
    "\n",
    "if(num_situ == 60):\n",
    "    glist = ['danr','CG14427','dan','CG43394','ImpL2','Nek2','CG8147','Ama','Btk29A','trn','numb','prd','brk','tsh','pxb','dpn','ftz','Kr','h','eve','Traf4','run','Blimp-1','lok','kni','tkv','MESR3','odd','noc','nub','Ilp4','aay','twi','bmm','hb','toc','rho','CG10479','gt','gk','apt','D','sna','NetA','Mdr49','fj','Mes2','CG11208','Doc2','bun','tll','Cyp310a1','Doc3','htl','Esp','bowl','oc','ImpE2','CG17724','fkh']\n",
    "elif(num_situ == 40):\n",
    "    glist = ['danr','CG14427','dan','CG43394','ImpL2','Nek2','CG8147','Ama','Btk29A','trn','numb','prd','brk','tsh','pxb','dpn','ftz','Kr','h','eve','Traf4','run','Blimp-1','lok','kni','tkv','MESR3','odd','noc','nub','Ilp4','aay','twi','bmm','hb','toc','rho','CG10479','gt','gk']\n",
    "elif(num_situ == 20):\n",
    "    glist = ['danr', 'CG14427', 'dan', 'CG43394', 'ImpL2', 'Nek2', 'CG8147', 'Ama', 'Btk29A', 'trn', 'numb', 'prd', 'brk', 'tsh', 'pxb', 'dpn', 'h', 'Traf4', 'run', 'toc']\n",
    "else:\n",
    "    raise ValueError('Undefined num_situ')\n",
    "\n",
    "def diff(first, second):\n",
    "        second = set(second)\n",
    "        return [item for item in first if item not in second]\n",
    "\n",
    "bdtnp_bin = pd.read_csv('../data/binarized_bdtnp.csv')[glist]\n",
    "dge_bin = pd.read_csv('../data/dge_binarized_distMap_T.csv')\n",
    "labels = pd.read_csv('../data/labels.csv') #This file contains the true locations for each cell (maximum 6 locations). E.g.:\n",
    "#loc1,loc2,loc3,loc4,loc5,loc6\n",
    "#133,,,,,\n",
    "#781,,,,,\n",
    "#...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Nov 19 11:37:26 2018 Create train input array for dge to bdtnp model\n",
      "0  100  200  300  400  500  600  700  800  900  1000  1100  1200  "
     ]
    }
   ],
   "source": [
    "print(time.ctime(), 'Create train input array for dge to bdtnp model')\n",
    "\n",
    "len_ = len(labels)\n",
    "X_ = np.empty((len_, 84))\n",
    "y_ = np.empty((len_, num_situ))\n",
    "\n",
    "for index, row in labels.iterrows():\n",
    "    if (index % 100 == 0):\n",
    "        print(index, ' ', end=\"\")\n",
    "    X_[index] = dge_bin.iloc[index]\n",
    "    y_[index] = bdtnp_bin.iloc[int(row[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Nov 19 11:37:29 2018 Model build\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 84)                0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 84)                7140      \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 84)                336       \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 84)                0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 40)                3400      \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 40)                160       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 60)                2460      \n",
      "=================================================================\n",
      "Total params: 13,496\n",
      "Trainable params: 13,248\n",
      "Non-trainable params: 248\n",
      "_________________________________________________________________\n",
      "None\n",
      "11:37:29  Fit\n",
      "Train on 1037 samples, validate on 260 samples\n",
      "Epoch 1/100\n",
      " - 2s - loss: 0.6192 - binary_accuracy: 0.6581 - val_loss: 0.4990 - val_binary_accuracy: 0.7745\n",
      "\n",
      "Epoch 00001: val_binary_accuracy improved from -inf to 0.77449, saving model to models/best_model.hdf5\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.5071 - binary_accuracy: 0.7534 - val_loss: 0.4367 - val_binary_accuracy: 0.8030\n",
      "\n",
      "Epoch 00002: val_binary_accuracy improved from 0.77449 to 0.80301, saving model to models/best_model.hdf5\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.4663 - binary_accuracy: 0.7776 - val_loss: 0.4044 - val_binary_accuracy: 0.8153\n",
      "\n",
      "Epoch 00003: val_binary_accuracy improved from 0.80301 to 0.81532, saving model to models/best_model.hdf5\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.4391 - binary_accuracy: 0.7893 - val_loss: 0.3853 - val_binary_accuracy: 0.8251\n",
      "\n",
      "Epoch 00004: val_binary_accuracy improved from 0.81532 to 0.82513, saving model to models/best_model.hdf5\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.4176 - binary_accuracy: 0.8039 - val_loss: 0.3651 - val_binary_accuracy: 0.8357\n",
      "\n",
      "Epoch 00005: val_binary_accuracy improved from 0.82513 to 0.83571, saving model to models/best_model.hdf5\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.4103 - binary_accuracy: 0.8068 - val_loss: 0.3503 - val_binary_accuracy: 0.8463\n",
      "\n",
      "Epoch 00006: val_binary_accuracy improved from 0.83571 to 0.84628, saving model to models/best_model.hdf5\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.3919 - binary_accuracy: 0.8155 - val_loss: 0.3375 - val_binary_accuracy: 0.8513\n",
      "\n",
      "Epoch 00007: val_binary_accuracy improved from 0.84628 to 0.85135, saving model to models/best_model.hdf5\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.3819 - binary_accuracy: 0.8227 - val_loss: 0.3267 - val_binary_accuracy: 0.8605\n",
      "\n",
      "Epoch 00008: val_binary_accuracy improved from 0.85135 to 0.86051, saving model to models/best_model.hdf5\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.3756 - binary_accuracy: 0.8272 - val_loss: 0.3184 - val_binary_accuracy: 0.8633\n",
      "\n",
      "Epoch 00009: val_binary_accuracy improved from 0.86051 to 0.86327, saving model to models/best_model.hdf5\n",
      "Epoch 10/100\n",
      " - 0s - loss: 0.3700 - binary_accuracy: 0.8294 - val_loss: 0.3107 - val_binary_accuracy: 0.8644\n",
      "\n",
      "Epoch 00010: val_binary_accuracy improved from 0.86327 to 0.86436, saving model to models/best_model.hdf5\n",
      "Epoch 11/100\n",
      " - 0s - loss: 0.3746 - binary_accuracy: 0.8258 - val_loss: 0.3039 - val_binary_accuracy: 0.8673\n",
      "\n",
      "Epoch 00011: val_binary_accuracy improved from 0.86436 to 0.86731, saving model to models/best_model.hdf5\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.3636 - binary_accuracy: 0.8315 - val_loss: 0.3009 - val_binary_accuracy: 0.8689\n",
      "\n",
      "Epoch 00012: val_binary_accuracy improved from 0.86731 to 0.86891, saving model to models/best_model.hdf5\n",
      "Epoch 13/100\n",
      " - 0s - loss: 0.3592 - binary_accuracy: 0.8347 - val_loss: 0.2964 - val_binary_accuracy: 0.8696\n",
      "\n",
      "Epoch 00013: val_binary_accuracy improved from 0.86891 to 0.86955, saving model to models/best_model.hdf5\n",
      "Epoch 14/100\n",
      " - 0s - loss: 0.3508 - binary_accuracy: 0.8368 - val_loss: 0.2926 - val_binary_accuracy: 0.8721\n",
      "\n",
      "Epoch 00014: val_binary_accuracy improved from 0.86955 to 0.87205, saving model to models/best_model.hdf5\n",
      "Epoch 15/100\n",
      " - 0s - loss: 0.3592 - binary_accuracy: 0.8361 - val_loss: 0.2895 - val_binary_accuracy: 0.8745\n",
      "\n",
      "Epoch 00015: val_binary_accuracy improved from 0.87205 to 0.87449, saving model to models/best_model.hdf5\n",
      "Epoch 16/100\n",
      " - 0s - loss: 0.3495 - binary_accuracy: 0.8399 - val_loss: 0.2868 - val_binary_accuracy: 0.8753\n",
      "\n",
      "Epoch 00016: val_binary_accuracy improved from 0.87449 to 0.87526, saving model to models/best_model.hdf5\n",
      "Epoch 17/100\n",
      " - 0s - loss: 0.3486 - binary_accuracy: 0.8416 - val_loss: 0.2836 - val_binary_accuracy: 0.8756\n",
      "\n",
      "Epoch 00017: val_binary_accuracy improved from 0.87526 to 0.87558, saving model to models/best_model.hdf5\n",
      "Epoch 18/100\n",
      " - 0s - loss: 0.3461 - binary_accuracy: 0.8428 - val_loss: 0.2825 - val_binary_accuracy: 0.8752\n",
      "\n",
      "Epoch 00018: val_binary_accuracy did not improve from 0.87558\n",
      "Epoch 19/100\n",
      " - 0s - loss: 0.3443 - binary_accuracy: 0.8432 - val_loss: 0.2808 - val_binary_accuracy: 0.8769\n",
      "\n",
      "Epoch 00019: val_binary_accuracy improved from 0.87558 to 0.87686, saving model to models/best_model.hdf5\n",
      "Epoch 20/100\n",
      " - 0s - loss: 0.3420 - binary_accuracy: 0.8438 - val_loss: 0.2787 - val_binary_accuracy: 0.8785\n",
      "\n",
      "Epoch 00020: val_binary_accuracy improved from 0.87686 to 0.87846, saving model to models/best_model.hdf5\n",
      "Epoch 21/100\n",
      " - 0s - loss: 0.3506 - binary_accuracy: 0.8395 - val_loss: 0.2786 - val_binary_accuracy: 0.8786\n",
      "\n",
      "Epoch 00021: val_binary_accuracy improved from 0.87846 to 0.87859, saving model to models/best_model.hdf5\n",
      "Epoch 22/100\n",
      " - 0s - loss: 0.3429 - binary_accuracy: 0.8449 - val_loss: 0.2764 - val_binary_accuracy: 0.8793\n",
      "\n",
      "Epoch 00022: val_binary_accuracy improved from 0.87859 to 0.87929, saving model to models/best_model.hdf5\n",
      "Epoch 23/100\n",
      " - 0s - loss: 0.3347 - binary_accuracy: 0.8476 - val_loss: 0.2750 - val_binary_accuracy: 0.8808\n",
      "\n",
      "Epoch 00023: val_binary_accuracy improved from 0.87929 to 0.88083, saving model to models/best_model.hdf5\n",
      "Epoch 24/100\n",
      " - 0s - loss: 0.3384 - binary_accuracy: 0.8460 - val_loss: 0.2744 - val_binary_accuracy: 0.8809\n",
      "\n",
      "Epoch 00024: val_binary_accuracy improved from 0.88083 to 0.88090, saving model to models/best_model.hdf5\n",
      "Epoch 25/100\n",
      " - 0s - loss: 0.3349 - binary_accuracy: 0.8467 - val_loss: 0.2740 - val_binary_accuracy: 0.8793\n",
      "\n",
      "Epoch 00025: val_binary_accuracy did not improve from 0.88090\n",
      "Epoch 26/100\n",
      " - 0s - loss: 0.3310 - binary_accuracy: 0.8493 - val_loss: 0.2731 - val_binary_accuracy: 0.8814\n",
      "\n",
      "Epoch 00026: val_binary_accuracy improved from 0.88090 to 0.88141, saving model to models/best_model.hdf5\n",
      "Epoch 27/100\n",
      " - 0s - loss: 0.3324 - binary_accuracy: 0.8503 - val_loss: 0.2724 - val_binary_accuracy: 0.8808\n",
      "\n",
      "Epoch 00027: val_binary_accuracy did not improve from 0.88141\n",
      "Epoch 28/100\n",
      " - 0s - loss: 0.3367 - binary_accuracy: 0.8489 - val_loss: 0.2729 - val_binary_accuracy: 0.8813\n",
      "\n",
      "Epoch 00028: val_binary_accuracy did not improve from 0.88141\n",
      "Epoch 29/100\n",
      " - 0s - loss: 0.3306 - binary_accuracy: 0.8505 - val_loss: 0.2721 - val_binary_accuracy: 0.8826\n",
      "\n",
      "Epoch 00029: val_binary_accuracy improved from 0.88141 to 0.88256, saving model to models/best_model.hdf5\n",
      "Epoch 30/100\n",
      " - 0s - loss: 0.3350 - binary_accuracy: 0.8473 - val_loss: 0.2700 - val_binary_accuracy: 0.8810\n",
      "\n",
      "Epoch 00030: val_binary_accuracy did not improve from 0.88256\n",
      "Epoch 31/100\n",
      " - 0s - loss: 0.3310 - binary_accuracy: 0.8509 - val_loss: 0.2701 - val_binary_accuracy: 0.8826\n",
      "\n",
      "Epoch 00031: val_binary_accuracy improved from 0.88256 to 0.88256, saving model to models/best_model.hdf5\n",
      "Epoch 32/100\n",
      " - 0s - loss: 0.3361 - binary_accuracy: 0.8472 - val_loss: 0.2694 - val_binary_accuracy: 0.8842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00032: val_binary_accuracy improved from 0.88256 to 0.88417, saving model to models/best_model.hdf5\n",
      "Epoch 33/100\n",
      " - 0s - loss: 0.3262 - binary_accuracy: 0.8527 - val_loss: 0.2704 - val_binary_accuracy: 0.8834\n",
      "\n",
      "Epoch 00033: val_binary_accuracy did not improve from 0.88417\n",
      "Epoch 34/100\n",
      " - 0s - loss: 0.3326 - binary_accuracy: 0.8482 - val_loss: 0.2689 - val_binary_accuracy: 0.8837\n",
      "\n",
      "Epoch 00034: val_binary_accuracy did not improve from 0.88417\n",
      "Epoch 35/100\n",
      " - 0s - loss: 0.3334 - binary_accuracy: 0.8500 - val_loss: 0.2678 - val_binary_accuracy: 0.8838\n",
      "\n",
      "Epoch 00035: val_binary_accuracy did not improve from 0.88417\n",
      "Epoch 36/100\n",
      " - 0s - loss: 0.3265 - binary_accuracy: 0.8520 - val_loss: 0.2685 - val_binary_accuracy: 0.8818\n",
      "\n",
      "Epoch 00036: val_binary_accuracy did not improve from 0.88417\n",
      "Epoch 37/100\n",
      " - 0s - loss: 0.3240 - binary_accuracy: 0.8552 - val_loss: 0.2678 - val_binary_accuracy: 0.8829\n",
      "\n",
      "Epoch 00037: val_binary_accuracy did not improve from 0.88417\n",
      "Epoch 38/100\n",
      " - 0s - loss: 0.3305 - binary_accuracy: 0.8516 - val_loss: 0.2670 - val_binary_accuracy: 0.8856\n",
      "\n",
      "Epoch 00038: val_binary_accuracy improved from 0.88417 to 0.88564, saving model to models/best_model.hdf5\n",
      "Epoch 39/100\n",
      " - 0s - loss: 0.3329 - binary_accuracy: 0.8504 - val_loss: 0.2673 - val_binary_accuracy: 0.8835\n",
      "\n",
      "Epoch 00039: val_binary_accuracy did not improve from 0.88564\n",
      "Epoch 40/100\n",
      " - 0s - loss: 0.3277 - binary_accuracy: 0.8516 - val_loss: 0.2681 - val_binary_accuracy: 0.8827\n",
      "\n",
      "Epoch 00040: val_binary_accuracy did not improve from 0.88564\n",
      "Epoch 41/100\n",
      " - 0s - loss: 0.3259 - binary_accuracy: 0.8511 - val_loss: 0.2667 - val_binary_accuracy: 0.8839\n",
      "\n",
      "Epoch 00041: val_binary_accuracy did not improve from 0.88564\n",
      "Epoch 42/100\n",
      " - 0s - loss: 0.3233 - binary_accuracy: 0.8546 - val_loss: 0.2655 - val_binary_accuracy: 0.8869\n",
      "\n",
      "Epoch 00042: val_binary_accuracy improved from 0.88564 to 0.88692, saving model to models/best_model.hdf5\n",
      "Epoch 43/100\n",
      " - 0s - loss: 0.3259 - binary_accuracy: 0.8541 - val_loss: 0.2657 - val_binary_accuracy: 0.8851\n",
      "\n",
      "Epoch 00043: val_binary_accuracy did not improve from 0.88692\n",
      "Epoch 44/100\n",
      " - 0s - loss: 0.3268 - binary_accuracy: 0.8524 - val_loss: 0.2665 - val_binary_accuracy: 0.8860\n",
      "\n",
      "Epoch 00044: val_binary_accuracy did not improve from 0.88692\n",
      "Epoch 45/100\n",
      " - 0s - loss: 0.3323 - binary_accuracy: 0.8501 - val_loss: 0.2655 - val_binary_accuracy: 0.8840\n",
      "\n",
      "Epoch 00045: val_binary_accuracy did not improve from 0.88692\n",
      "Epoch 46/100\n",
      " - 0s - loss: 0.3274 - binary_accuracy: 0.8519 - val_loss: 0.2645 - val_binary_accuracy: 0.8848\n",
      "\n",
      "Epoch 00046: val_binary_accuracy did not improve from 0.88692\n",
      "Epoch 47/100\n",
      " - 0s - loss: 0.3187 - binary_accuracy: 0.8576 - val_loss: 0.2634 - val_binary_accuracy: 0.8865\n",
      "\n",
      "Epoch 00047: val_binary_accuracy did not improve from 0.88692\n",
      "Epoch 48/100\n",
      " - 0s - loss: 0.3279 - binary_accuracy: 0.8522 - val_loss: 0.2640 - val_binary_accuracy: 0.8855\n",
      "\n",
      "Epoch 00048: val_binary_accuracy did not improve from 0.88692\n",
      "Epoch 49/100\n",
      " - 0s - loss: 0.3235 - binary_accuracy: 0.8558 - val_loss: 0.2645 - val_binary_accuracy: 0.8838\n",
      "\n",
      "Epoch 00049: val_binary_accuracy did not improve from 0.88692\n",
      "Epoch 50/100\n",
      " - 0s - loss: 0.3219 - binary_accuracy: 0.8550 - val_loss: 0.2628 - val_binary_accuracy: 0.8869\n",
      "\n",
      "Epoch 00050: val_binary_accuracy did not improve from 0.88692\n",
      "Epoch 51/100\n",
      " - 0s - loss: 0.3244 - binary_accuracy: 0.8531 - val_loss: 0.2640 - val_binary_accuracy: 0.8863\n",
      "\n",
      "Epoch 00051: val_binary_accuracy did not improve from 0.88692\n",
      "Epoch 52/100\n",
      " - 0s - loss: 0.3180 - binary_accuracy: 0.8581 - val_loss: 0.2618 - val_binary_accuracy: 0.8869\n",
      "\n",
      "Epoch 00052: val_binary_accuracy did not improve from 0.88692\n",
      "Epoch 53/100\n",
      " - 0s - loss: 0.3250 - binary_accuracy: 0.8550 - val_loss: 0.2617 - val_binary_accuracy: 0.8879\n",
      "\n",
      "Epoch 00053: val_binary_accuracy improved from 0.88692 to 0.88795, saving model to models/best_model.hdf5\n",
      "Epoch 54/100\n",
      " - 0s - loss: 0.3221 - binary_accuracy: 0.8554 - val_loss: 0.2632 - val_binary_accuracy: 0.8854\n",
      "\n",
      "Epoch 00054: val_binary_accuracy did not improve from 0.88795\n",
      "Epoch 55/100\n",
      " - 0s - loss: 0.3182 - binary_accuracy: 0.8538 - val_loss: 0.2633 - val_binary_accuracy: 0.8867\n",
      "\n",
      "Epoch 00055: val_binary_accuracy did not improve from 0.88795\n",
      "Epoch 56/100\n",
      " - 0s - loss: 0.3235 - binary_accuracy: 0.8548 - val_loss: 0.2620 - val_binary_accuracy: 0.8875\n",
      "\n",
      "Epoch 00056: val_binary_accuracy did not improve from 0.88795\n",
      "Epoch 57/100\n",
      " - 0s - loss: 0.3146 - binary_accuracy: 0.8597 - val_loss: 0.2631 - val_binary_accuracy: 0.8864\n",
      "\n",
      "Epoch 00057: val_binary_accuracy did not improve from 0.88795\n",
      "Epoch 58/100\n",
      " - 0s - loss: 0.3179 - binary_accuracy: 0.8564 - val_loss: 0.2637 - val_binary_accuracy: 0.8857\n",
      "\n",
      "Epoch 00058: val_binary_accuracy did not improve from 0.88795\n",
      "Epoch 59/100\n",
      " - 0s - loss: 0.3216 - binary_accuracy: 0.8568 - val_loss: 0.2642 - val_binary_accuracy: 0.8858\n",
      "\n",
      "Epoch 00059: val_binary_accuracy did not improve from 0.88795\n",
      "Epoch 60/100\n",
      " - 0s - loss: 0.3208 - binary_accuracy: 0.8563 - val_loss: 0.2629 - val_binary_accuracy: 0.8858\n",
      "\n",
      "Epoch 00060: val_binary_accuracy did not improve from 0.88795\n",
      "Epoch 61/100\n",
      " - 0s - loss: 0.3225 - binary_accuracy: 0.8561 - val_loss: 0.2632 - val_binary_accuracy: 0.8862\n",
      "\n",
      "Epoch 00061: val_binary_accuracy did not improve from 0.88795\n",
      "Epoch 62/100\n",
      " - 0s - loss: 0.3173 - binary_accuracy: 0.8577 - val_loss: 0.2620 - val_binary_accuracy: 0.8851\n",
      "\n",
      "Epoch 00062: val_binary_accuracy did not improve from 0.88795\n",
      "Epoch 63/100\n",
      " - 0s - loss: 0.3178 - binary_accuracy: 0.8588 - val_loss: 0.2626 - val_binary_accuracy: 0.8869\n",
      "\n",
      "Epoch 00063: val_binary_accuracy did not improve from 0.88795\n",
      "Epoch 64/100\n",
      " - 0s - loss: 0.3194 - binary_accuracy: 0.8555 - val_loss: 0.2626 - val_binary_accuracy: 0.8858\n",
      "\n",
      "Epoch 00064: val_binary_accuracy did not improve from 0.88795\n",
      "Epoch 65/100\n",
      " - 0s - loss: 0.3193 - binary_accuracy: 0.8574 - val_loss: 0.2619 - val_binary_accuracy: 0.8861\n",
      "\n",
      "Epoch 00065: val_binary_accuracy did not improve from 0.88795\n",
      "Epoch 66/100\n",
      " - 0s - loss: 0.3208 - binary_accuracy: 0.8556 - val_loss: 0.2623 - val_binary_accuracy: 0.8870\n",
      "\n",
      "Epoch 00066: val_binary_accuracy did not improve from 0.88795\n",
      "Epoch 67/100\n",
      " - 0s - loss: 0.3135 - binary_accuracy: 0.8596 - val_loss: 0.2607 - val_binary_accuracy: 0.8878\n",
      "\n",
      "Epoch 00067: val_binary_accuracy did not improve from 0.88795\n",
      "Epoch 68/100\n",
      " - 0s - loss: 0.3148 - binary_accuracy: 0.8586 - val_loss: 0.2624 - val_binary_accuracy: 0.8865\n",
      "\n",
      "Epoch 00068: val_binary_accuracy did not improve from 0.88795\n",
      "Epoch 69/100\n",
      " - 0s - loss: 0.3119 - binary_accuracy: 0.8604 - val_loss: 0.2610 - val_binary_accuracy: 0.8860\n",
      "\n",
      "Epoch 00069: val_binary_accuracy did not improve from 0.88795\n",
      "Epoch 70/100\n",
      " - 0s - loss: 0.3178 - binary_accuracy: 0.8585 - val_loss: 0.2607 - val_binary_accuracy: 0.8874\n",
      "\n",
      "Epoch 00070: val_binary_accuracy did not improve from 0.88795\n",
      "Epoch 71/100\n",
      " - 0s - loss: 0.3169 - binary_accuracy: 0.8590 - val_loss: 0.2607 - val_binary_accuracy: 0.8878\n",
      "\n",
      "Epoch 00071: val_binary_accuracy did not improve from 0.88795\n",
      "Epoch 72/100\n",
      " - 0s - loss: 0.3131 - binary_accuracy: 0.8582 - val_loss: 0.2615 - val_binary_accuracy: 0.8876\n",
      "\n",
      "Epoch 00072: val_binary_accuracy did not improve from 0.88795\n",
      "Epoch 73/100\n",
      " - 0s - loss: 0.3170 - binary_accuracy: 0.8569 - val_loss: 0.2596 - val_binary_accuracy: 0.8882\n",
      "\n",
      "Epoch 00073: val_binary_accuracy improved from 0.88795 to 0.88821, saving model to models/best_model.hdf5\n",
      "Epoch 74/100\n",
      " - 0s - loss: 0.3202 - binary_accuracy: 0.8552 - val_loss: 0.2606 - val_binary_accuracy: 0.8862\n",
      "\n",
      "Epoch 00074: val_binary_accuracy did not improve from 0.88821\n",
      "Epoch 75/100\n",
      " - 0s - loss: 0.3123 - binary_accuracy: 0.8594 - val_loss: 0.2602 - val_binary_accuracy: 0.8865\n",
      "\n",
      "Epoch 00075: val_binary_accuracy did not improve from 0.88821\n",
      "Epoch 76/100\n",
      " - 0s - loss: 0.3169 - binary_accuracy: 0.8584 - val_loss: 0.2611 - val_binary_accuracy: 0.8876\n",
      "\n",
      "Epoch 00076: val_binary_accuracy did not improve from 0.88821\n",
      "Epoch 77/100\n",
      " - 0s - loss: 0.3189 - binary_accuracy: 0.8570 - val_loss: 0.2600 - val_binary_accuracy: 0.8884\n",
      "\n",
      "Epoch 00077: val_binary_accuracy improved from 0.88821 to 0.88840, saving model to models/best_model.hdf5\n",
      "Epoch 78/100\n",
      " - 0s - loss: 0.3240 - binary_accuracy: 0.8572 - val_loss: 0.2610 - val_binary_accuracy: 0.8878\n",
      "\n",
      "Epoch 00078: val_binary_accuracy did not improve from 0.88840\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.3080 - binary_accuracy: 0.8638 - val_loss: 0.2602 - val_binary_accuracy: 0.8894\n",
      "\n",
      "Epoch 00079: val_binary_accuracy improved from 0.88840 to 0.88936, saving model to models/best_model.hdf5\n",
      "Epoch 80/100\n",
      " - 0s - loss: 0.3165 - binary_accuracy: 0.8582 - val_loss: 0.2597 - val_binary_accuracy: 0.8881\n",
      "\n",
      "Epoch 00080: val_binary_accuracy did not improve from 0.88936\n",
      "Epoch 81/100\n",
      " - 0s - loss: 0.3150 - binary_accuracy: 0.8589 - val_loss: 0.2601 - val_binary_accuracy: 0.8858\n",
      "\n",
      "Epoch 00081: val_binary_accuracy did not improve from 0.88936\n",
      "Epoch 82/100\n",
      " - 0s - loss: 0.3125 - binary_accuracy: 0.8605 - val_loss: 0.2594 - val_binary_accuracy: 0.8884\n",
      "\n",
      "Epoch 00082: val_binary_accuracy did not improve from 0.88936\n",
      "Epoch 83/100\n",
      " - 0s - loss: 0.3130 - binary_accuracy: 0.8595 - val_loss: 0.2590 - val_binary_accuracy: 0.8877\n",
      "\n",
      "Epoch 00083: val_binary_accuracy did not improve from 0.88936\n",
      "Epoch 84/100\n",
      " - 0s - loss: 0.3209 - binary_accuracy: 0.8573 - val_loss: 0.2593 - val_binary_accuracy: 0.8887\n",
      "\n",
      "Epoch 00084: val_binary_accuracy did not improve from 0.88936\n",
      "Epoch 85/100\n",
      " - 0s - loss: 0.3137 - binary_accuracy: 0.8601 - val_loss: 0.2578 - val_binary_accuracy: 0.8890\n",
      "\n",
      "Epoch 00085: val_binary_accuracy did not improve from 0.88936\n",
      "Epoch 86/100\n",
      " - 0s - loss: 0.3119 - binary_accuracy: 0.8605 - val_loss: 0.2583 - val_binary_accuracy: 0.8896\n",
      "\n",
      "Epoch 00086: val_binary_accuracy improved from 0.88936 to 0.88955, saving model to models/best_model.hdf5\n",
      "Epoch 87/100\n",
      " - 0s - loss: 0.3168 - binary_accuracy: 0.8584 - val_loss: 0.2587 - val_binary_accuracy: 0.8879\n",
      "\n",
      "Epoch 00087: val_binary_accuracy did not improve from 0.88955\n",
      "Epoch 88/100\n",
      " - 0s - loss: 0.3059 - binary_accuracy: 0.8624 - val_loss: 0.2587 - val_binary_accuracy: 0.8883\n",
      "\n",
      "Epoch 00088: val_binary_accuracy did not improve from 0.88955\n",
      "Epoch 89/100\n",
      " - 0s - loss: 0.3087 - binary_accuracy: 0.8621 - val_loss: 0.2583 - val_binary_accuracy: 0.8892\n",
      "\n",
      "Epoch 00089: val_binary_accuracy did not improve from 0.88955\n",
      "Epoch 90/100\n",
      " - 0s - loss: 0.3101 - binary_accuracy: 0.8623 - val_loss: 0.2586 - val_binary_accuracy: 0.8869\n",
      "\n",
      "Epoch 00090: val_binary_accuracy did not improve from 0.88955\n",
      "Epoch 91/100\n",
      " - 0s - loss: 0.3141 - binary_accuracy: 0.8585 - val_loss: 0.2576 - val_binary_accuracy: 0.8873\n",
      "\n",
      "Epoch 00091: val_binary_accuracy did not improve from 0.88955\n",
      "Epoch 92/100\n",
      " - 0s - loss: 0.3158 - binary_accuracy: 0.8584 - val_loss: 0.2578 - val_binary_accuracy: 0.8880\n",
      "\n",
      "Epoch 00092: val_binary_accuracy did not improve from 0.88955\n",
      "Epoch 93/100\n",
      " - 0s - loss: 0.3113 - binary_accuracy: 0.8607 - val_loss: 0.2584 - val_binary_accuracy: 0.8881\n",
      "\n",
      "Epoch 00093: val_binary_accuracy did not improve from 0.88955\n",
      "Epoch 94/100\n",
      " - 0s - loss: 0.3194 - binary_accuracy: 0.8591 - val_loss: 0.2584 - val_binary_accuracy: 0.8882\n",
      "\n",
      "Epoch 00094: val_binary_accuracy did not improve from 0.88955\n",
      "Epoch 95/100\n",
      " - 0s - loss: 0.3129 - binary_accuracy: 0.8602 - val_loss: 0.2558 - val_binary_accuracy: 0.8899\n",
      "\n",
      "Epoch 00095: val_binary_accuracy improved from 0.88955 to 0.88987, saving model to models/best_model.hdf5\n",
      "Epoch 96/100\n",
      " - 0s - loss: 0.3096 - binary_accuracy: 0.8607 - val_loss: 0.2573 - val_binary_accuracy: 0.8888\n",
      "\n",
      "Epoch 00096: val_binary_accuracy did not improve from 0.88987\n",
      "Epoch 97/100\n",
      " - 0s - loss: 0.3092 - binary_accuracy: 0.8614 - val_loss: 0.2560 - val_binary_accuracy: 0.8890\n",
      "\n",
      "Epoch 00097: val_binary_accuracy did not improve from 0.88987\n",
      "Epoch 98/100\n",
      " - 0s - loss: 0.3110 - binary_accuracy: 0.8608 - val_loss: 0.2570 - val_binary_accuracy: 0.8863\n",
      "\n",
      "Epoch 00098: val_binary_accuracy did not improve from 0.88987\n",
      "Epoch 99/100\n",
      " - 0s - loss: 0.3061 - binary_accuracy: 0.8643 - val_loss: 0.2573 - val_binary_accuracy: 0.8885\n",
      "\n",
      "Epoch 00099: val_binary_accuracy did not improve from 0.88987\n",
      "Epoch 100/100\n",
      " - 0s - loss: 0.3044 - binary_accuracy: 0.8632 - val_loss: 0.2570 - val_binary_accuracy: 0.8882\n",
      "\n",
      "Epoch 00100: val_binary_accuracy did not improve from 0.88987\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2748ee50c18>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model build for dge to bdtnp.\n",
    "print(time.ctime(), 'Model build')\n",
    "\n",
    "a1 = Input(shape=(84,))\n",
    "e = Dense(84)(a1)\n",
    "e = BatchNormalization()(e)\n",
    "e = Dropout(0.3)(e)\n",
    "e = Dense(40)(e)\n",
    "e = BatchNormalization()(e)\n",
    "e = Activation('softplus')(e)\n",
    "e = Dropout(0.2)(e)\n",
    "\n",
    "output = Dense(num_situ, activation='sigmoid')(e)\n",
    "model = Model(inputs=[a1], outputs=[output])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
    "print(model.summary())\n",
    "print(time.strftime(\"%H:%M:%S\"), ' Fit')\n",
    "\n",
    "# checkpoint\n",
    "filepath=\"models/best_model.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_binary_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "model.fit(  x=[X_], y=y_,\n",
    "            batch_size=10,\n",
    "            epochs=100,\n",
    "            verbose=2,\n",
    "            validation_split=0.2,\n",
    "            callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using The Models - Max(MCC) and ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0,2)(100,2)(200,2)(300,2)(400,2)(500,2)(600,2)(700,3)(800,4)(900,2)(1000,2)(1100,3)(1200,2)"
     ]
    }
   ],
   "source": [
    "#Optimized calculation of MCC, using matrices (row-wise between two matrices)\n",
    "def MCC(bd, dg):\n",
    "    #Calculate TN times TP\n",
    "    TP = np.matmul(dg,bd)\n",
    "    TN = np.matmul(1 - dg, 1 - bd)\n",
    "    FP = np.matmul(dg, 1 - bd)\n",
    "    FN = np.matmul(1 - dg, bd)\n",
    "    numerator = TN*TP - FP*FN\n",
    "    denominator = 1/np.sqrt((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN) + sys.float_info.epsilon)\n",
    "    MCC = numerator*denominator\n",
    "    return(MCC)\n",
    "\n",
    "\n",
    "ind = {}\n",
    "mcc = MCC(bdtnp_bin.T, dge_bin[glist])\n",
    "inx = 0\n",
    "results = pd.DataFrame()\n",
    "\n",
    "for row in mcc:\n",
    "    if (inx % 100 == 0):\n",
    "        print(f'({inx},{lis_len})', end=\"\")\n",
    "    row_sorted = row.copy()\n",
    "    row_sorted.sort()\n",
    "    \n",
    "    #In some cases Max(MCC) provides less than 10 locations in the top n. In these cases we want to include them 'for sure'\n",
    "    #hence to exclude them from the ANN considerations.\n",
    "    #Trial and error show that (for 40 and 60 sub-challenves) we need to consider Max(MCC) model up to the 2'nd place only.\n",
    "    closest = []\n",
    "    candidates1 = []\n",
    "    lis_len = len(np.argwhere(row >= row_sorted[-2]))\n",
    "    if(lis_len <= 10 and num_situ > 20):\n",
    "        candidates1 = np.ndarray.flatten(np.argwhere(row >= row_sorted[-2])).tolist()\n",
    "    \n",
    "    if(lis_len < 10 or num_situ == 20):\n",
    "        #Using ANN model to select 10 locations out of a list of candidates.\n",
    "        if(num_situ > 20):\n",
    "            n = 10 # Consider only tops Max(MCC) in case of 60 and 40 sub-challenge\n",
    "        else:\n",
    "            n = 3037 # Ignore Max(MCC) altogether in case of 20 sub-challenge.\n",
    "        candidates2 = np.ndarray.flatten(np.argwhere(row >= row_sorted[-n]))\n",
    "        candidates2 = diff(candidates2, candidates1)\n",
    "        pred = model.predict(dge_bin.iloc[inx][np.newaxis,:], batch_size=1, verbose=0)[0]\n",
    "\n",
    "        #Loop 10 times and select the locations in BDTNP that are closest to ANN predictions (on the candidates).\n",
    "        bdt = bdtnp_bin.copy().iloc[candidates2]\n",
    "        closest = []\n",
    "        for i in range(0, 10 - len(candidates1)):\n",
    "            temp_closest = pairwise_distances_argmin(pred.reshape(1, -1), bdt)\n",
    "            #Zero out the current location selected, so it wont be picked in the next loop.\n",
    "            bdt.iloc[temp_closest[0]].values[:] = 0\n",
    "            closest = closest + [candidates2[temp_closest[0]]]\n",
    "\n",
    "    ind[inx] = candidates1 + closest\n",
    "    results = pd.concat([results, pd.DataFrame(ind[inx]).T.reset_index(drop=True)])\n",
    "    inx += 1\n",
    "\n",
    "\n",
    "#Save for submission. Submission file is not zero-based.\n",
    "results = results + 1\n",
    "results.to_csv(f'maxmcc_{num_situ}_plus_one.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sanity Check The Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of matched labels: 1589, real labels count: 1691\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "real_count = 0\n",
    "k = 0\n",
    "\n",
    "#for i,val in true_labels.items():\n",
    "for index, row in labels.iterrows():\n",
    "    real_count = real_count + np.count_nonzero(~np.isnan(row))\n",
    "    for j in ind[k]:\n",
    "        if(j in row.values):\n",
    "            count = count + 1\n",
    "    k = k + 1\n",
    "\n",
    "print(f'Count of matched labels: {count}, real labels count: {real_count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix - Gene Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max(MCC) optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to select the best genes for the model we need to consider the following goal:\n",
    "- Max(MCC) should properly reflect the true locations.\n",
    "\n",
    "Hence when we have a maximal value for two rows (from BDTNP and DGE) using 84 in-situ genes, we\n",
    "want it to stay maximal even if we drop to a smaller in-situ gene set. Since there are too many combinations for selecting (say) 20 genes\n",
    "out of 84, we instead use a heuristic approach. Removing one gene at a time, and calculating how many matched locations, have now\n",
    "moved back from maximal value, to less than the top 10. We need to preserve genes that maximize that number (i.e. as a result\n",
    "of removing them many locations 'fall off' the list of top high 10 max(mcc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdtnp_bin = pd.read_csv('../data/binarized_bdtnp.csv')\n",
    "dge_bin = pd.read_csv('../data/dge_binarized_distMap_T.csv')\n",
    "glist_84 = ['aay','Ama','Ance','Antp','apt','Blimp-1','bmm','bowl','brk','Btk29A','bun','cad','CenG1A','CG10479','CG11208','CG14427','CG17724','CG17786','CG43394','CG8147','cnc','croc','Cyp310a1','D','dan','danr','Dfd','disco','Doc2','Doc3','dpn','edl','ems','erm','Esp','E(spl)m5-HLH','eve','exex','fj','fkh','ftz','gk','gt','h','hb','hkb','htl','Ilp4','ImpE2','ImpL2','ken','kni','knrl','Kr','lok','Mdr49','Mes2','MESR3','mfas','Nek2','NetA','noc','nub','numb','oc','odd','peb','prd','pxb','rau','rho','run','sna','srp','tkv','tll','toc','Traf4','trn','tsh','twi','zen','zen2','zfh1']\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for i in range(0,num_situ):\n",
    "    glist_83 = glist_84.copy()\n",
    "    glist_83.remove(glist_84[i])\n",
    "    bd = bdtnp_bin[glist_83].copy()\n",
    "    dg = dge_bin[glist_83].copy()\n",
    "    \n",
    "    #Calculate MCC\n",
    "    mcc = MCC(dg.T,bd)\n",
    "    \n",
    "    cell_ind = 0\n",
    "    num_outs = 0\n",
    "    #Using calculation of MCC on all 3039 cells, we can check the affect of removing a gene\n",
    "    #on the 'score': check how many true labels are 'out' of the ten max values (max cells).\n",
    "    #We look for genes that maximize that number.\n",
    "    for row in mcc.T:\n",
    "        row_sorted = row.copy()\n",
    "        row_sorted.sort()\n",
    "        largest_ = np.argwhere(row > row_sorted[-10])\n",
    "        len_list = np.count_nonzero(~np.isnan(labels.iloc[cell_ind]))\n",
    "        for j in range(0,len_list):\n",
    "            if(not labels.iloc[cell_ind,:len_list][j] in largest_):\n",
    "                num_outs = num_outs + 1\n",
    "        cell_ind += 1\n",
    "\n",
    "    print(f'{i} ', end=\"\")\n",
    "    df = pd.concat([df, pd.DataFrame({'gene':glist_84[i], 'num_outs':num_outs}, index=[0])])\n",
    "\n",
    "list(df.sort_values('num_outs', ascending=False).head(num_situ).gene)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In this approach we try to maximize the result for the ANN model.\n",
    "- In order to achieve best performance (accuracy) of the ANN, we need to target (BTDNP rows) to be as much different as possible.\n",
    "- This is crucial for the 20 genes sub-challenge since for improper gene selection we will get many rows from BDTNP with the *same* value.\n",
    "- Hence no model will be able to distinguish betweeen any two rows.\n",
    "- Again, we are faced with the problem of how to select 20 genes out of 80, and we decided to solve using heuristics.\n",
    "- We start with a 'good enough' list - a list of genes that has as many '1's as possible in the columns.\n",
    "    - We assume that genes with lots of '1' will cause many BDTNP lines to be different.\n",
    "- We then imrove the result using the following code that cycles through all combinations of 20 out of 80 genes, and tries to find\n",
    "a set that maximizes the number of different rows in BDTNP.\n",
    "    - Note that this code can be optimized in two ways:\n",
    "        - Adding randomization of selection of 20 genes groups.\n",
    "        - Using GPUs (i.e. rewrite the code in Tensorflow).\n",
    "\n",
    "NOTE: DON'T RUN THIS ON THE NOTEBOOK AS IT CONSUMES THE CPU (RUN IT AS A STANDALONE PYTHON PROGRAM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found new set, size:1553\n",
      "['danr', 'CG14427', 'dan', 'CG43394', 'ImpL2', 'Nek2', 'CG8147', 'Ama', 'Btk29A', 'trn', 'numb', 'prd', 'brk', 'tsh', 'pxb', 'dpn', 'ftz', 'Kr', 'h', 'eve']\n",
      "Found new set, size:1635\n",
      "['danr', 'CG14427', 'dan', 'CG43394', 'ImpL2', 'Nek2', 'CG8147', 'Ama', 'Btk29A', 'trn', 'numb', 'prd', 'brk', 'tsh', 'pxb', 'dpn', 'ftz', 'Kr', 'h', 'Traf4']\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations as cs\n",
    "\n",
    "#The followin list of genes are the ones that have as many '1' in the columns as possible ('danr' has the most).\n",
    "#The algorithm starts with the right-most gene and tries to improve. The result is the list of 20 genes shown on the first cell.\n",
    "list_84 = ['danr', 'CG14427', 'dan', 'CG43394', 'ImpL2', 'Nek2', 'CG8147', 'Ama', 'Btk29A', 'trn', 'numb', 'prd', 'brk', 'tsh', 'pxb', 'dpn', 'ftz', 'Kr', 'h', 'eve', 'Traf4', 'run', 'Blimp-1', 'lok', 'kni', 'tkv', 'MESR3', 'odd', 'noc', 'nub', 'Ilp4', 'aay', 'twi', 'bmm', 'hb', 'toc', 'rho', 'CG10479', 'gt', 'gk', 'apt', 'D', 'sna', 'NetA', 'Mdr49', 'fj', 'Mes2', 'CG11208', 'Doc2', 'bun', 'tll', 'Cyp310a1', 'Doc3', 'htl', 'Esp', 'bowl', 'oc', 'ImpE2', 'CG17724', 'fkh', 'edl', 'ems', 'zen2', 'CG17786', 'zen', 'disco', 'Dfd', 'mfas', 'knrl', 'Ance', 'croc', 'rau', 'cnc', 'exex', 'cad', 'Antp', 'erm', 'ken', 'peb', 'srp', 'E(spl)m5-HLH', 'CenG1A', 'zfh1', 'hkb']\n",
    "bd = pd.read_csv('../data/binarized_bdtnp.csv')[list_84]\n",
    "\n",
    "inx = 0\n",
    "previous_size = 0\n",
    "previous_list = []\n",
    "for tup in cs(bd.columns, 20):\n",
    "    temp_bd = bd[list(tup)]\n",
    "    temp_size = len(temp_bd.groupby(temp_bd.columns.tolist(), as_index=False).size())\n",
    "    if(temp_size > previous_size):\n",
    "        print(f'Found new set, size:{temp_size}')\n",
    "        print(list(tup))\n",
    "        previous_size = temp_size\n",
    "        previous_list = list(tup)\n",
    "    if (inx % 10000 == 0):\n",
    "        print(f'inx={inx})\n",
    "        print(f'Current tuple: {tup}')\n",
    "    inx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
