{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dream Challenge Solution Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"toc\"></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook handles the 60, 40 and 20 genes sub-challenges. It uses a combination of two models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Model - Max(MCC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- First model is based on calculating MAX(MCC) using only 60(40 or 20) genes as opposed to using 84 genes.\n",
    "- Calculating of MCC is done using matrix multiplication.\n",
    "- A list of 'candidates' for locations is assembeled using the MAX(MCC) calculation.\n",
    "- This list is then refined using the second model.\n",
    "- In the case of 60 genes, MAX(MCC) gives a very good results (location prediction). The second model is hardly needed in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Model - ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The second model is a simple ANN to forecast BTDNP sequences given a DGE sequence.\n",
    "- Input: a row from binarized DGE.\n",
    "- Output: a prediction for a row from binarized BDTNP (the correct location).\n",
    "- It is used to 'correct' the MAX(MCC) results.\n",
    "- The advatage of this model is being able to predict correct gene patterns (as opposed to just maximizing MCC, i.e. location).\n",
    "- The model is relyies on a correct selction of subsets of 60/40/20 genes.\n",
    "- In the case of 20 genes - it is the only model used since the MAX(MCC) is totally off."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining The Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- How to combine the two models?\n",
    "- We have 10 possibilities (locations) for each cell. We let Max(MCC) propose candidates and then 'correct' the result and select the best candidates using the ANN model.\n",
    "- If Max(MCC) propose less than 10 results - it means these are very strong results, and we keep them. Otherwise we ignore the results and use only ANN model.\n",
    "- A manual calibration was done to decide how many candidates we want from the Max(MCC) model. This means selecting the 'cutoff' value of MCC such that we take all locations above this value as a candidate for a location.\n",
    "    - In case of 60 genes trial and error gives an optimal selection of the 2'nd MCC score as a cutoff.\n",
    "    - In case of 40 genese optimal solution is taking the top 2'nd score using Max(MCC) as a cutoff.\n",
    "    - In case of 20 genes all 10 locations are decided using ANN (we are not using the Max(MCC) model at all.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Make sure you installed Python 3 with SKLearn (we used Anaconda), Tensorflow and Keras.\n",
    "- Just run the following cells one by one.\n",
    "- This notebook has to be run three times - for the 60, 40 and 20 genes sub-challenge.\n",
    "- Manual configuration:\n",
    "    - In the following cell - configure num_situ as the number of in-situ genes (sub-challenge) to use. Either 60, 40 or 20."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build an ANN Model for DGE->BDTNP Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import pairwise_distances_argmin\n",
    "import keras\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Dense, Embedding, concatenate, Flatten, Dropout, Lambda, Activation, BatchNormalization, LocallyConnected1D, Reshape, AlphaDropout, Conv1D, MaxPooling1D\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import time\n",
    "import sys\n",
    "\n",
    "######################################################\n",
    "# This is the only parameter you need to configure.  #\n",
    "# It has to be run three times (60, 40 and 20 genes.)#\n",
    "######################################################\n",
    "num_situ = 20\n",
    "\n",
    "if(num_situ == 60):\n",
    "    glist = ['danr','CG14427','dan','CG43394','ImpL2','Nek2','CG8147','Ama','Btk29A','trn','numb','prd','brk','tsh','pxb','dpn','ftz','Kr','h','eve','Traf4','run','Blimp-1','lok','kni','tkv','MESR3','odd','noc','nub','Ilp4','aay','twi','bmm','hb','toc','rho','CG10479','gt','gk','apt','D','sna','NetA','Mdr49','fj','Mes2','CG11208','Doc2','bun','tll','Cyp310a1','Doc3','htl','Esp','bowl','oc','ImpE2','CG17724','fkh']\n",
    "elif(num_situ == 40):\n",
    "    glist = ['danr','CG14427','dan','CG43394','ImpL2','Nek2','CG8147','Ama','Btk29A','trn','numb','prd','brk','tsh','pxb','dpn','ftz','Kr','h','eve','Traf4','run','Blimp-1','lok','kni','tkv','MESR3','odd','noc','nub','Ilp4','aay','twi','bmm','hb','toc','rho','CG10479','gt','gk']\n",
    "elif(num_situ == 20):\n",
    "    glist = ['danr', 'CG14427', 'dan', 'CG43394', 'ImpL2', 'Nek2', 'CG8147', 'Ama', 'Btk29A', 'trn', 'numb', 'prd', 'brk', 'tsh', 'pxb', 'dpn', 'h', 'Traf4', 'run', 'toc']\n",
    "else:\n",
    "    raise ValueError('Undefined num_situ')\n",
    "\n",
    "def diff(first, second):\n",
    "        second = set(second)\n",
    "        return [item for item in first if item not in second]\n",
    "\n",
    "bdtnp_bin = pd.read_csv('binarized_bdtnp.csv')[glist]\n",
    "dge_bin = pd.read_csv('dge_binarized_distMap_T.csv')\n",
    "labels = pd.read_csv('labels.csv') #This file contains the true locations for each cell (maximum 6 locations). E.g.:\n",
    "#loc1,loc2,loc3,loc4,loc5,loc6\n",
    "#133,,,,,\n",
    "#781,,,,,\n",
    "#...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Nov 19 11:37:26 2018 Create train input array for dge to bdtnp model\n",
      "0  100  200  300  400  500  600  700  800  900  1000  1100  1200  "
     ]
    }
   ],
   "source": [
    "print(time.ctime(), 'Create train input array for dge to bdtnp model')\n",
    "\n",
    "len_ = len(labels)\n",
    "X_ = np.empty((len_, 84))\n",
    "y_ = np.empty((len_, num_situ))\n",
    "\n",
    "for index, row in labels.iterrows():\n",
    "    if (index % 100 == 0):\n",
    "        print(index, ' ', end=\"\")\n",
    "    X_[index] = dge_bin.iloc[index]\n",
    "    y_[index] = bdtnp_bin.iloc[int(row[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model build for dge to bdtnp.\n",
    "print(time.ctime(), 'Model build')\n",
    "\n",
    "a1 = Input(shape=(84,))\n",
    "e = Dense(84)(a1)\n",
    "e = BatchNormalization()(e)\n",
    "e = Dropout(0.3)(e)\n",
    "e = Dense(40)(e)\n",
    "e = BatchNormalization()(e)\n",
    "e = Activation('softplus')(e)\n",
    "e = Dropout(0.2)(e)\n",
    "\n",
    "output = Dense(num_situ, activation='sigmoid')(e)\n",
    "model = Model(inputs=[a1], outputs=[output])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
    "print(model.summary())\n",
    "print(time.strftime(\"%H:%M:%S\"), ' Fit')\n",
    "\n",
    "# checkpoint\n",
    "filepath=\"models/best_model.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_binary_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "model.fit(  x=[X_], y=y_,\n",
    "            batch_size=10,\n",
    "            epochs=100,\n",
    "            verbose=2,\n",
    "            validation_split=0.2,\n",
    "            callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using The Models - Max(MCC) and ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0)(100)(200)(300)(400)(500)(600)(700)(800)(900)(1000)(1100)(1200)"
     ]
    }
   ],
   "source": [
    "#Optimized calculation of MCC, using matrices (row-wise between two matrices)\n",
    "def MCC(bd, dg):\n",
    "    #Calculate TN times TP\n",
    "    TP = np.matmul(dg,bd)\n",
    "    TN = np.matmul(1 - dg, 1 - bd)\n",
    "    FP = np.matmul(dg, 1 - bd)\n",
    "    FN = np.matmul(1 - dg, bd)\n",
    "    numerator = TN*TP - FP*FN\n",
    "    denominator = 1/np.sqrt((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN) + sys.float_info.epsilon)\n",
    "    MCC = numerator*denominator\n",
    "    return(MCC)\n",
    "\n",
    "\n",
    "ind = {}\n",
    "mcc = MCC(bdtnp_bin.T, dge_bin[glist])\n",
    "inx = 0\n",
    "results = pd.DataFrame()\n",
    "\n",
    "for row in mcc:\n",
    "    if (inx % 100 == 0):\n",
    "        print(f'({inx})', end=\"\")\n",
    "    row_sorted = row.copy()\n",
    "    row_sorted.sort()\n",
    "    \n",
    "    #In some cases Max(MCC) provides less than 10 locations in the top n. In these cases we want to include them 'for sure'\n",
    "    #hence to exclude them from the ANN considerations.\n",
    "    #Trial and error show that (for 40 and 60 sub-challenves) we need to consider Max(MCC) model up to the 2'nd place only.\n",
    "    closest = []\n",
    "    candidates1 = []\n",
    "    lis_len = len(np.argwhere(row >= row_sorted[-2]))\n",
    "    if(lis_len <= 10 and num_situ > 20):\n",
    "        candidates1 = np.ndarray.flatten(np.argwhere(row >= row_sorted[-2])).tolist()\n",
    "    elif(lis_len > 10):\n",
    "        #Sometimes even taking the top 2 elements gives more than 10 candidates. In that case ignore them.\n",
    "        lis_len = 0\n",
    "        candidates1 = []\n",
    "        \n",
    "    if(lis_len < 10 or num_situ == 20):\n",
    "        #Using ANN model to select 10 locations out of a list of candidates.\n",
    "        if(num_situ > 20):\n",
    "            n = 10 # Consider only tops Max(MCC) in case of 60 and 40 sub-challenge\n",
    "        else:\n",
    "            n = 3037 # Ignore Max(MCC) altogether in case of 20 sub-challenge.\n",
    "        candidates2 = np.ndarray.flatten(np.argwhere(row >= row_sorted[-n]))\n",
    "        candidates2 = diff(candidates2, candidates1)\n",
    "        pred = model.predict(dge_bin.iloc[inx][np.newaxis,:], batch_size=1, verbose=0)[0]\n",
    "\n",
    "        #Loop 10 times and select the locations in BDTNP that are closest to ANN predictions (on the candidates).\n",
    "        bdt = bdtnp_bin.copy().iloc[candidates2]\n",
    "        closest = []\n",
    "        for i in range(0, 10 - len(candidates1)):\n",
    "            temp_closest = pairwise_distances_argmin(pred.reshape(1, -1), bdt)\n",
    "            #Zero out the current location selected, so it wont be picked in the next loop.\n",
    "            bdt.iloc[temp_closest[0]].values[:] = -100\n",
    "            closest = closest + [candidates2[temp_closest[0]]]\n",
    "\n",
    "    ind[inx] = candidates1 + closest\n",
    "    results = pd.concat([results, pd.DataFrame(ind[inx]).T.reset_index(drop=True)])\n",
    "    inx += 1\n",
    "\n",
    "\n",
    "#Save for submission. Submission file is not zero-based.\n",
    "results = results + 1\n",
    "results.to_csv(f'maxmcc_{num_situ}_plus_one.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sanity Check The Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of matched labels: 874, real labels count: 1691\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "real_count = 0\n",
    "k = 0\n",
    "\n",
    "#for i,val in true_labels.items():\n",
    "for index, row in labels.iterrows():\n",
    "    real_count = real_count + np.count_nonzero(~np.isnan(row))\n",
    "    for j in ind[k]:\n",
    "        if(j in row.values):\n",
    "            count = count + 1\n",
    "    k = k + 1\n",
    "\n",
    "print(f'Count of matched labels: {count}, real labels count: {real_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
